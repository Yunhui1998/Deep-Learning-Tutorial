## 13 特殊应用：人脸识别和神经风格转换

### 13.1 什么是人脸识别？

#### 13.1.1 人脸验证 vs 人脸识别

**人脸验证**(face verification)：也被称为 “1对1” 问题。

- 输入：一张图片以及某人的ID或名字
- 输出：系统验证输入图片是否是这个人。

**人脸识别**(face recognition)：“1对K” 问题。

- 拥有一个包含 $K$ 人信息的数据库
- 输入：一张图片
- 输出：若输入图片符合 $K$ 人中任意一个人的图像，输出这个人的ID，否则，输出"not recognized"。

**人脸验证与人脸识别的关系：**

​		人脸识别比人脸验证要求更高。假设有一个验证系统准确率是99%，看起来这个验证系统性能不错，但如果应用到有100个人的数据库的人脸识别系统中，每个人的犯错概率是1%，整体犯错概率就放大了100倍，所以要想得到一个可接受的识别误差，就要构造一个准确率为99%甚至更高的验证系统才能得到很好的识别效果。也就是说，人脸验证系统的准确率要足够高才能应用到人脸识别系统中。

#### 13.1.2 人脸识别的传统方法

主流的人脸识别技术基本上可以归结为三类，即：基于几何特征的方法、基于模板的方法和基于模型的方法。

- 基于几何特征的方法是最早、最传统的方法，通常需要和其他算法结合才能有比较好的效果；
-  基于模板的方法可以分为基于相关匹配的方法、特征脸方法、线性判别分析方法、奇异值分解方法、神经网络方法、动态连接匹配方法等。
- 基于模型的方法则有基于隐马尔柯夫模型，主动形状模型和主动外观模型的方法等。

下文主要介绍三种传统的人脸识别方法：

1. 主成分分析法

​       主成分分析法(PAC，Principal Component Analysis)又称为特征脸法，是20世纪90年代初由Turk和Pentland提出的一种经典算法，根据图像的统计特征通过正交变换（即K-L变换）由高维向量转换为低维向量，并形成低维线性向量空间，利用人脸投影到这个低维空间所得到的投影系数作为识别的特征矢量，这样，就产生了一个由“特征脸”矢量形成的子空间，成为“人脸子空间”或“特征子空间”，每一幅人脸图像向其投影都可以获得一组坐标系数，这组坐标系数表明了人脸在子空间中的位置，因此利用特征脸方法可以重建和识别人脸。

2. 线性判别分析

​       线性判别分析是对费舍尔的线性鉴别方法的归纳，这种方法使用统计学、模式识别和机器学习方法，试图找到两类物体或事件的特征的一个线性组合，以能够特征化或区分它们。所得的组合可用来作为一个线性分类器，或者，更常见的是，为后续的分类做降维处理。

3. 支持向量机

​        支持向量机（SVM，Support Vector Machine）起源于统计学习理论，研究如何构造学籍及，实现模式分类问题。其基本思想是通过非线性变换将输入空间变换到一个高维空间，在高维空间求取最优线性分类面，以解决那些线性不可分的分类问题。而这种非线性变换是通过定义适当的内积函数（即核函数）来实现的，由于该方法是基于结构风险最小化原理，而不是传统统计学的经验风险最小化，因而表现出很多优于已有方法的性能，但该方法需要大量的存储空间，并且训练速度慢。

> 参考：
>
> 1. https://www.jiqizhixin.com/articles/2019-02-10-4
> 2. https://wenku.baidu.com/view/34c55025a100a6c30c22590102020740be1ecdb7.html

### 13.2 One-Shot学习

#### 13.2.1 One-Shot学习的定义

**One-Shot learning**：一次学习，只通过一个样本来进行学习以能够认出同一个人。

![](http://m.qpic.cn/psc?/V50v5bPV1er4BO1DcJVb3iyeFd3aL3dx/ruAMsa53pVQWN7FLK88i5iLp7pNWJ5zmfdGFIdQo3o1DbLBe1PdpXIMPY3..xYUUuVQU3W6zMdXUAQJaDIqS4QgGkVNy2tVPG1a4SPQ1*Vs!/b&bo=HAFOAQAAAAADB3A!&rf=viewer_4)

如上图所示，假设人脸识别系统数据库里有4个人每人一张照片，需要仅仅通过每个人的一张照片来判断输入图片中是否含有这4个人的其中一个。

#### 13.2.2 如何解决One-Shot学习问题

对于One-Shot学习问题，采用卷积神经网络进行识别分类的缺点：

1. 训练集太小，不足以训练一个稳健的神经网络；
2. 如果有新成员加入数据集，分类输出的标签数量要改变，神经网络得重新训练。

故要解决One-Shot学习问题，应该要**学习Similarity函数**（也称为d函数）：
$$
\begin{equation}\begin{split}
d(img1,&img2)=degree\ of\ difference\ between\ images\\[2ex]
&If\ d(img1,img2)\ \le\ \tau\ \ \ \ "same"\\
&If\ d(img1,img2)\ \ge\ \tau\ \ \ \ "different"\\
\end{split}\end{equation}
$$
以两张图片作为输入，然后输出这两张图片的差异值，差异值越小越相似。如果差异值小于某个阈值 $\tau$（$\tau$ 是一个超参数），就预测输入的是同一个人的两张图片；如果差异值大于阈值，就预测输入的是两个不同的人的照片，从而实现人脸验证。

将其应用于人脸识别任务，分别将要预测的图片及数据库中的任一张图片输入，用d函数两两比较，如果有输出一个比阈值小的数字，则预测的图片就是那个人的照片，若没有，则要预测的人不是数据库中的任一个人。

![](http://m.qpic.cn/psc?/V50v5bPV1er4BO1DcJVb3iyeFd3aL3dx/ruAMsa53pVQWN7FLK88i5vvIkID5DOHuzIh1uab4y2PZb6b95akXozOGyKNVP6TNmeLPrUmdrL3jJIBoj*.ZtGoUcJphHiu0*p*o4MxAkRs!/b&bo=GAFVAQAAAAADB28!&rf=viewer_4)

在上面这个例子中，首先输入要识别的图片和数据库中第一张图片，输出一个很大的值，说明不是同一个人；接着输入要识别的图片和数据库中第二张图片，输出一个很小的值，很可能是同一个人；再分别输入要识别的图片和数据库中第三、四张图片，输出的值都很大，不是同一个人。因此，要识别的图片是第二个人的。若输出的值都很大，则要识别的人不是数据库里的任一个人。

如果要加入新成员，只需将其照片加入数据库中，系统依然能照常工作。

#### 13.2.3 Few-Shot learning

**Few-Shot learning**：小样本学习，用很少的样本去做分类或者回归。

Few-Shot  learning与传统的监督学习算法不同，它的目标不是让机器识别训练集中图片并且泛化到测试集，而是**让机器自己学会学习**。可以理解为用一个小数据集训练神经网络，学习的目的不是让神经网络知道每个类别是什么，而是让模型理解事物的异同，学会区分不同的事物。

![](https://pic3.zhimg.com/v2-fd151eb30787d73c9186149b5a19f382_r.jpg)

比如上面这张图片，左边两张图是同一种动物，右边两张是同一种动物，Few-Shot  learning要做的就是通过对上面这四张图的学习判断下面这张图是属于哪一种动物。

![](https://pic3.zhimg.com/v2-f5182305b19c25f26a50ef7bace7a462_r.jpg)

Few-Shot learning 问题的关键是解决过拟合 (overfitting) 的问题，因为训练的样本太少了，训练出的模型可能在训练集上效果还行，但是在测试集上面会遭遇灾难性的崩塌。

**解决方法：**

1. 数据增强和正则化：这一类方法想法很直接简单，既然训练数据不够那就增加训练样本，既然过拟合那就使用正则化技术。
   - 数据加强：最常见的例子就是有时对 Omniglot 数据集的预处理，会将图片旋转 90 、180 、270 度，这样就可以使样本数量变为原来的 4 倍。
   - 正则化：在训练的时候加入一个正则项，这个正则项的构建选择是关键。比如 《Few-shot Classification on Graphs  with Structural Regularized GCNs》。该论文讨论 Graph 中节点分类的 few-shot  问题，常见的节点分类是使用 GCN 从节点的特征向量 feature 学习一个 embedding 然后用 embedding 来做分类，如果是 few-shot 问题，性能会大大下降（准确率大约从 70% 到了 40%），作者在训练的时候给损失函数加了一个正则项。作者将 feature 到 embedding 的过程看成编码器 encoder，然后额外加了几层网络作为 decoder，将 embedding 重构为  feature ，然后重构误差作为正则项（准确率从 40% 提升了 50%，大约 10  个百分点）。

2. Meta-learning（元学习）：核心想法是先学习一个先验知识（prior），这个先验知识对解决 few-shot learning 问题特别有帮助。也就是说，先学习很多很多 task，然后再来解决新的在之前的学习中没有见过的 task 。

> 参考：
>
> 1. https://blog.csdn.net/weixin_37589575/article/details/92801610
> 2. https://zhuanlan.zhihu.com/p/142381922

### 13.3 Siamese网络

Siamese网络架构是实现Similarity函数的一种方式。

#### 13.3.1 Siamese网络架构

**Siamese网络架构**：对于两个不同的输入，运行相同的卷积神经网络，然后比较它们输出的特征向量从而判断是否是属于同一类。

![](http://m.qpic.cn/psc?/V50v5bPV1er4BO1DcJVb3iyeFd3aL3dx/ruAMsa53pVQWN7FLK88i5hHTEinaIAjdphrwELBFVZtmygqbyR*5TioxJ2.08k7uwO5DdPI8J5ub7xrfzCmzPPAK1WZ1zLnMmM*V*QnSibw!/b&bo=TgIfAQAAAAADB3A!&rf=viewer_4)

如上图所示，首先将第一张输入图像$x^{(1)}$送入卷积神经网络，经过一系列的卷积、池化、全连接后输出一个特征向量，将这个特征向量称为$f(x^{(1)})$，看作是输入图像$x^{(1)}$的编码；然后将第二张输入图像$x^{(2)}$送入同样的神经网络，也得到一个特征向量，称为$f(x^{(2)})$，代表输入图像$x^{(2)}$的编码。我们相信这两个编码可以很好地代表两张输入图像，故定义d函数为两张图片编码之差的范数：
$$
d(x^{(1)}, x^{(2)})=||f(x^{(1)})-f(x^{(2)})||_2^2
$$

#### 13.3.2 如何训练Siamese网络

由于Siamese网络中两个卷积神经网络是一样的，所以在训练Siamese网络时只需要训练一个就好。

![](http://m.qpic.cn/psc?/V50v5bPV1er4BO1DcJVb3iyeFd3aL3dx/ruAMsa53pVQWN7FLK88i5kyQxXjeXItUlno96UewOHlDdqia7oO0ctqg8WAYTwGC5jpAh1k7TYd6wpeYRu4B2IJ3G3PvI35cHt8GSkt6vZA!/b&bo=CQIbAQAAAAADBzM!&rf=viewer_4)

更准确地说，神经网络的参数定义了一个编码函数$f(x^{(i)})$，如果给定输入图像$x^{(i)}$，会输出$x^{(i)}$的一个编码（特征向量）。训练网络要做的就是学习参数，使得如果两个图片$x^{(i)}$和$x^{(j)}$是同一个人，得到的两个编码的距离就小；如果$x^{(i)}$和$x^{(j)}$是不同的人，则它们之间的编码距离会比较大。如果改变这个网络所有层的参数，会得到不同的编码结果，要用反向传播来改变这些所有的参数以确保满足上面的条件。

### 13.4 Triplet损失

#### 13.4.1 Triplet损失的定义

**Triplet loss**：三元组损失，通常需要同时看三张图片：Anchor图片（A）、Positive图片（P，即正类，跟Anchor是同一个人）和Negative图片（N，即负类，跟Anchor不是同一个人）。其中，A和P为一对，是同一个人，所以希望它们编码的距离很接近；A和N为一对，不是同一个人，所以希望它们编码的距离远一点。公式如下：
$$
||f(A)-f(P)||^2 \le ||f(A)-f(N)||^2
$$
即：$d(A,P) \le d(A,N)$

把方程右边项移到左边：
$$
||f(A)-f(P)||^2-||f(A)-f(N)||^2 \le 0
$$

有两种情况满足这个表达式但没有用处：

1. 所有的编码会总是输出0，即$f(img)=0$，则 $0-0=0$。
2. 把所有的编码都设成相等的，即如果每个图片的编码和其他图片一样，这种情况还是得到 $0-0=0$。

为了阻止网络出现这两种情况，应该把“小于等于0”这个目标改为“小于0”，故将目标改为“$0-\alpha$”（$\alpha$是一个超参数），由于我们更习惯使用“$+\ \alpha$”，所以将“$-\ \alpha$”这项移到左边，得到：
$$
||f(A)-f(P)||^2-||f(A)-f(N)||^2 \ +\ \alpha \le 0
$$

故第一个式子也变为：
$$
||f(A)-f(P)||^2\ +\ \alpha \le ||f(A)-f(N)||^2
$$

其中，$\alpha$也叫做间隔（margin），假设间隔设为0.2，为了满足条件，可以把d(A, N)调大或者把d(A, P)调小让间隔至少是0.2，这样就拉大了anchor与positive图片对和anchor与negative图片对之间的差距。例如，假设d(A, P)等于0.5，如果d(A, N)只比d(A, P)大一点点，为0.51，就不能满足条件，因为我们想让d(A, N)比d(A, P)大很多，至少是0.7或者更高。

#### 13.4.2 Triplet损失函数

对于**一个三元组定义的损失函数**：
$$
L(A,P,N)=max(||f(A)-f(P)||^2-||f(A)-f(N)||^2 \ +\ \alpha,0)
$$
若$||f(A)-f(P)||^2-||f(A)-f(N)||^2 \ +\ \alpha$ 小于0，那么损失函数就是0；若大于0，则损失函数等于$||f(A)-f(P)||^2-||f(A)-f(N)||^2 \ +\ \alpha$ ，是一个正的损失值。通过最小化损失函数，只要这个损失函数等于0，达到的效果就是使$||f(A)-f(P)||^2-||f(A)-f(N)||^2 \ +\ \alpha$小于或等于0，网络不会关心它的负值有多大。

**整个网络的代价函数**是训练集中这些单个三元组损失的总和：
$$
J=\sum_{i=1}^mL(A^{(i)},P^{(i)},N^{(i)})
$$
假设有一个10000张图片的训练集，里面是1000个不同的人的照片，平均每人10张照片，要做的是取这10000张图片生成三元组，然后对代价函数用梯度下降从而训练学习算法，训练完成后就可以应用到一次学习问题中。

为了定义三元组的数据集，需要成对的A和P即同一个人的成对的图片，

#### 13.4.3 如何选择三元组组成训练集

倘若从数据集中随机地选择A, P, N构成三元组，遵循A和P是同一个人而A和N是不同的人这一原则，则不是同一个人的概率比是同一个人的概率大很多，即d(A, N)比d(A, P)大$\alpha$ 的概率很大，目标很容易就达到，网络很轻松就能训练好，梯度算法不会有什么效果。

所以应该**尽可能选择难训练的三元组A P N即所有的三元组d(A, P)都很接近d(A, N)**，这样，学习算法就会竭尽全力使d(A, N)变大或者使d(A, P)变小使得二者之间至少间隔$\alpha$，并且选择这样的三元组训练难度大，梯度下降法才能发挥作用，从而增加学习算法的计算效率。

![](http://m.qpic.cn/psc?/V50v5bPV1er4BO1DcJVb3iyeFd3aL3dx/ruAMsa53pVQWN7FLK88i5tmii3IyfkwfgqZh3ebx3n0Kurqa1NggUXshIPzA5bihLW1agkKoo.jIEriGVdRNqy*s5EK8iolD6ixGg3rcnHc!/b&bo=*gJOAgAAAAADB5I!&rf=viewer_4)

### 13.5 面部验证与二分类

#### 13.5.1 将人脸识别变成二分类问题

Triplet loss是个学习人脸识别卷积网络参数的好方法，此外还有其他学习参数的方法，如将人脸识别当成一个二分类问题：

![](https://upload-images.jianshu.io/upload_images/24408091-b1134844ca5c34c5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

选取一对神经网络，选用 Siamese 网络并使其同时计算这些特征向量，然后将其输入到逻辑回归单元进行预测，若是相同的人，那么输出是 1，若是不同的人，输出是 0。这就把人脸识别问题转换为一个二分类问题，训练这种系统时可以替换 Triplet loss的方法。

#### 13.5.2 逻辑回归单元的处理

最后通过将sigmoid等函数应用到某些特征上来处理逻辑回归单元：
$$
\hat{y}=\sigma\left(\sum_{k=1}^{128} w_{i}\left|f\left(x^{(i)}\right)_{k}-f\left(x^{(j)}\right)_{k}\right|+b\right)
$$
其中，符号$f\left(x^{(i)}\right)$代表图片$x^{(i)}$的编码，下标 $k$ 代表选择这个向量中的第$k$个元素，$\left|f\left(x^{(i)}\right)_{k}-f\left(x^{(j)}\right)_{k}\right|$对这两个编码取元素差的绝对值。就像普通的逻辑回归一样，把这128个元素当作特征，然后把他们放入逻辑回归中，最后的逻辑回归可以增加参数$w_{i}$和$b$。在这128个单元上训练合适的权重，用来预测两张图片是否是一个人。

还可以用$\chi^{2}$公式$\frac{\left(f\left(x^{(i)}\right)_{k}-f\left(x^{(j)}\right)_{k}\right)^{2}}{f\left(x^{(i)}\right)_{k}+f\left(x^{(j)}\right)_{k}}$，也被称作$\chi$平方相似度，来代替上式中$\left|f\left(x^{(i)}\right)_{k}-f\left(x^{(j)}\right)_{k}\right|$的计算。

#### 13.5.3 预先计算思想

在上面的学习公式中，输入是一对图片($x^{(i)}$和$x^{(j)}$)，输出$y$是0或者1取决于输入是相似图片还是非相似图片。与之前类似，训练一个Siamese网络，即两个神经网络拥有的参数是相同的，两组参数是绑定的。

**预先计算好数据库中图片的编码可以节省大量的计算，显著提高部署效果。**

如你有一张新图片$x^{(i)}$，当员工走进门时，希望门可以自动为他打开，在数据库中的图片$x^{(j)}$，不需要每次都计算特征向量，可以提前计算好，那么当一个新员工走近时，可以使用上方的卷积网络来计算编码，然后将其和预先计算好的编码进行比较，输出预测值 $\hat{y}$。

**总结**：把人脸验证当作一个监督学习，创建一个只有成对图片的训练集，不是三个一组，而是成对的图片，目标标签是1表示这对图片是一个人，目标标签是0表示图片中是不同的人。利用不同的成对图片，使用反向传播算法去训练神经网络，训练Siamese神经网络。

### 13.6 什么是神经风格迁移

#### 13.6.1 神经风格迁移的定义

![](https://upload-images.jianshu.io/upload_images/24408091-13d07a09cc7511c9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

比如这张照片，你想利用右边照片的风格来重新创造原本的照片，右边的是梵高的星空，神经风格迁移可以帮你生成下面这张照片。使用$C$来表示内容图像，$S$表示风格图像，$G$表示生成的图像。

#### 13.6.2 神经风格迁移的常用方法

![img](https://image.jiqizhixin.com/uploads/editor/8b3794f3-f283-4854-a34a-d95f9c94a910/1526351820525.png)

[参考博客]: https://www.jiqizhixin.com/articles/2018-05-15-5	"综述：图像风格化算法最全盘点 | 内附大量扩展应用"

### 13.7 深度卷积网络在学什么

#### 13.7.1 可视化分析卷积神经网络的浅层

假如训练了一个卷积神经网络，是一个Alexnet，轻量级网络，希望将看到不同层之间隐藏单元的计算结果。

![](https://upload-images.jianshu.io/upload_images/24408091-2691704e7e4a6539.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

你可以这样做，从第一层的隐藏单元开始，假设你遍历了训练集，然后找到那些使得单元激活最大化的一些图片或是图片块。换句话说，将你的训练集经过神经网络，然后弄明白哪一张图片最大限度地激活特定的单元。注意在第一层的隐藏单元，只能看到小部分卷积神经，如果要画出来哪些激活了激活单元，只有一小块图片块是有意义的，因为这就是特定单元所能看到的全部。你选择一个隐藏单元，发现有9个图片最大化了单元激活，你可能找到这样的9个图片块（左上九宫格），似乎是图片浅层区域显示了隐藏单元所看到的，找到了像这样的边缘或者线（上面的蓝格子），这就是那9个最大化地激活了隐藏单元激活项的图片块。

![](https://upload-images.jianshu.io/upload_images/24408091-10e4bdaf11b9eba7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

然后你可以选一个另一个第一层的隐藏单元，重复刚才的步骤，这是另一个隐藏单元，似乎第二个由这9个图片块（上中九宫格）组成。看来这个隐藏单元在输入区域，寻找这样的线条（下面的蓝格子），我们也称之为接受域。

对其他隐藏单元也进行处理，会发现其他隐藏单元趋向于激活类似于这样的图片。右上九宫格似乎对垂直明亮边缘且左边是绿色的图片块感兴趣，左中九宫格的隐藏单元倾向于橘色图片块。

以此类推，这是9个不同的代表性神经元，每一个不同的图片块都最大化地激活了。你可以这样理解，第一层的隐藏单元通常会找一些简单的特征，比如说边缘或者颜色阴影。

#### 13.7.2 可视化分析卷积神经网络的深层

在深层部分，一个隐藏单元会看到一张图片更大的部分，在极端的情况下，可以假设每一个像素都会影响到神经网络更深层的输出，靠后的隐藏单元可以看到更大的图片块。

![](https://upload-images.jianshu.io/upload_images/24408091-16abece5006d21e3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上图中Layer 1是之前第一层得到的，Layer 2是可视化的第2层中最大程度激活的9个隐藏单元。在更深的层上，可以重复这个过程。

放大第一层，这是第一个被高度激活的单元，你能在输入图片的区域看到所提取的这些边缘或颜色阴影。

![](https://upload-images.jianshu.io/upload_images/24408091-42ef17313aa9534a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

放大第二层的可视化图像。第二层似乎检测到更复杂的形状和模式，比如说中上九宫格这一隐藏单元会找到有很多垂线的垂直图案，右中九宫格的隐藏单元似乎在左侧有圆形图案时会被高度激活，左下九宫格所寻找的特征是很细的垂线，以此类推，第二层检测的特征变得更加复杂。

![](https://upload-images.jianshu.io/upload_images/24408091-a9eb50d09bcf0edd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

放大第三层，这些东西激活了第三层。中心九宫格这一隐藏单元似乎对图像左下角的圆形很敏感，所以检测到很多车。右下九宫格似乎开始检测到人类，左上九宫格似乎检测特定的图案，比如蜂窝形状或者方形这样类似规律的图案。有些很难看出来，需要手动弄明白检测到什么，但是第三层明显，检测到更复杂的模式。

![](https://upload-images.jianshu.io/upload_images/24408091-3f826b746dd74787.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



这是第四层，检测到的模式和特征更加复杂，左上九宫格学习成了一个狗的检测器，但是这些狗看起来都很类似。右中九宫格似乎检测到鸟的脚等等。

<img src="https://upload-images.jianshu.io/upload_images/24408091-f91edfd99863138c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:80%;" />



第五层检测到更加复杂的事物，右下九宫格似乎是一个狗检测器，但是可以检测到的狗似乎更加多样性。左上九宫格可以检测到键盘或者是键盘质地的物体，可能是有很多点的物体。左中九宫格可能检测到文本，但是很难确定，左下九宫格检测到花。

<img src="https://upload-images.jianshu.io/upload_images/24408091-1fc734a2551bf4df.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:80%;" />

由此，我们已经有了一些进展，**从检测简单的事物，比如说，第一层的边缘，第二层的质地，到深层的复杂物体**，更直观地了解卷积神经网络的浅层和深层是如何计算的。

### 13.8 代价函数

#### 13.8.1 代价函数的作用

神经风格迁移系统用代价函数来评判某个生成图像的好坏。

#### 13.8.2 代价函数的定义

$$
J(G)=αJ_{content}(C,G)+βJ_{style}(S,G)
$$

其中，$J_{content}(C,G)$称为内容代价函数，用来衡量生成图片G的内容与图片C的内容有多相似；$J_{style}(S,G)$是风格代价函数，用来衡量图片G的风格与图片S的风格的相似度。超参数 $\alpha$ 和 $\beta$ 确定内容代价和风格代价两者之间的权重。

#### 13.8.2 如何最小化代价函数

用梯度下降法来最小化代价函数：
$$
G=G-\frac{\partial}{\partial G}J(G)
$$
实际上每次更新的是图像G的像素值。举个例子：

![](http://m.qpic.cn/psc?/V50v5bPV1er4BO1DcJVb3iyeFd3aL3dx/ruAMsa53pVQWN7FLK88i5t.eifHmZyC21.eKz8oiLigbTw4weWgpxutDwwSjvcy4xldmghl*5gZZIvy23TlnMOjTE6qfXmWaKJR8uVoTHKY!/b&bo=eQGEAAAAAAADB94!&rf=viewer_4)

要取上图中左边图片的内容和右边图片的风格生成图像G。随机初始化的生成图像如下图①所示，是一张随机选取像素的白噪声图；接下来运行梯度下降算法，最小化代价函数$J(G)$，逐步处理像素，逐步得到越来越像用风格图片的风格画出来的内容图片（下图中第②-④张图片）。

![](http://m.qpic.cn/psc?/V50v5bPV1er4BO1DcJVb3iyeFd3aL3dx/ruAMsa53pVQWN7FLK88i5nftd.qb6*kgFabQY2o160N7Tlab3uvMAlbum4ps0lYZVZfklei3rUVkF58RRGZwOXz2Q66taCyi6vvPswALTPk!/b&bo=*AAmAgAAAAADB*o!&rf=viewer_4)

### 13.9 内容代价函数

#### 13.9.1 定义

内容代价函数：Content cost function，衡量内容图片和生成图片在内容上的相似度。

假如用隐含层 $l$ 来计算内容代价，$l$ 一般是选在网络的中间层，不会选的太浅或太深。然后用一个预训练的卷积模型，$a^{[l](C)}$和$a^{[l](G)}$分别代表内容图片C和生成图片G的 $l$ 层的激活函数值。如果这两个激活值相似，则这两张图片的内容相似。故将内容代价函数定义为两个激活值的不同或相似程度，即其差值的平方：
$$
J_{content}(C,G)=\frac{1}{2}||a^{[l](C)}-a^{[l](G)}||^2
$$
其中，$\frac{1}{2}$ 是对其进行归一化，可以不加也可以是其他值，因为在整体代价函数中还可由超参数 $\alpha$ 调整内容代价函数的权重。

### 13.10 风格代价函数

风格代价函数：Style cost function，衡量风格图片和生成图片在风格上的相似度。

#### 13.10.1 图像风格的定义

如下图所示，假如有这么一张图片输入卷积网络，对于某一隐藏层 $l$ ，图片的风格可以定义为 $l$ 层中各个通道之间激活项的相关系数。

![](http://m.qpic.cn/psc?/V50v5bPV1er4BO1DcJVb3iyeFd3aL3dx/ruAMsa53pVQWN7FLK88i5hIokQDoQ.2bQqeX.rsV*hygBw2rAgAe4xJUdtZgnYsEsqwsDuuuFHHE5lbW6z2y8qY2rayLTlpzKxDApVnhUdE!/b&bo=RwJsAAAAAAADBws!&rf=viewer_4)

具体解释：

将 $l$ 层的激活项取出，是一个 $n_H \times n_W \times n_C$ 的三维激活项，将其不同通道渲染成不同的颜色，每个通道对应一个神经元，如下图所示，以前两个通道为例，红色通道对应的是第二个神经元(红色方框)，能找出图片中的特定位置是否含有垂线纹理，黄色通道对应第四个神经元(黄色方框)，可以粗略找出橙色区域，则这两个通道的相关系数指的就是图片中某处出现这种垂直纹理时该处又同时是橙色的可能性。若采用相关系数来描述通道的风格，则需测量生成图像中第一个通道是否与第二个通道相关，从而得知在生成图像中垂直纹理和橙色同时出现或不同时出现的概率，这样就能够测量生成图像的风格与输入的风格图像的相似程度。

![](http://m.qpic.cn/psc?/V50v5bPV1er4BO1DcJVb3iyeFd3aL3dx/ruAMsa53pVQWN7FLK88i5hsSmHqQZw7u5bYU9v9fChKE2v*40F5D46czPz11RnEbJF8oRSUTi*EuhspeII4Bn6uTPxBnJ7KUxhZ3ZlxyFI8!/b&bo=hwFGAgAAAAADB.A!&rf=viewer_4)



#### 13.10.2 风格矩阵

对于风格图像与生成图像，需要计算其风格矩阵，说得更具体一点就是用 $l$ 层来测量风格。

假设 $a^{[l]}_{i,j,k}$ 为隐藏层 $l$ 中 $(i,j,k)$ 位置的激活项，i、j、k分别代表该位置的高度、宽度以及对应的通道数。现在要计算一个关于 $l$ 层和风格图像的矩阵 $G^{[l][S]}$ （ $l$ 表示层数，$S$ 表示风格图像），由于有 $n_c$ 个通道，故 $G^{[l][S]}$ 是一个 $n_c \times n_c$ 的矩阵，以便计算 $k$ 通道和 $k′$ 通道中每一对激活项的相关系数， $k$ 和 $k′$ 的取值范围则为$1,2,...,n_c$，
设这个关于 $l$ 层和风格图像的矩阵 $G^{[l][S]}$ 高度和宽度都是 $l$ 层的通道数，在这个矩阵中 $k$ 和 $k′$ 元素被用来描述 $k$ 通道和 $k′$ 通道之间的相关系数，则风格图像的风格矩阵是：
$$
G^{[l](S)}_{kk'}=\sum_i^{n^{[l]}_H} \sum_j^{n^{[l]}_W} a_{ijk}^{[l](S)}a_{ijk'}^{[l](S)}
$$
其中，符号 $i$、$j$ 表示下界，对 $i$、$j$、$k$ 位置的激活项 $a_{ijk}^{[l](S)}$，乘以同样位置即 $i$、$j$、$k'$ 位置的激活项 $a_{ijk'}^{[l](S)}$，然后 $i$、$j$ 分别加到 $l$ 层的高度和宽度，即 $n^{[l]}_H$ 和 $n^{[l]}_W$，将这些不同位置的激活项都加起来即可得到风格矩阵。严格来说，这个公式是一种非标准的互相关函数，因为没有将其减去平均数，而是将它们直接相乘。

对生成图像做同样的操作即可得到生成图像的风格矩阵：
$$
G^{[l](G)}_{kk'}=\sum_i^{n^{[l]}_H} \sum_j^{n^{[l]}_W} a_{ijk}^{[l](G)}a_{ijk'}^{[l](G)}
$$

之所以用大写字母 $G$ 来代表这些风格矩阵，是因为在线性代数中这种矩阵有时也叫 Gram 矩阵，但在这里只把它们叫做风格矩阵。

如果两个通道中的激活项数值都很大，那么 $G^{[l]}_{kk'}$ 也会很大，对应地，如果它们不相关那么 $G^{[l]}_{kk'}$ 就会很小。

下图形象地展示了风格矩阵的形成过程：

![](http://m.qpic.cn/psc?/V50v5bPV1er4BO1DcJVb3iyeFd3aL3dx/ruAMsa53pVQWN7FLK88i5jITwsOckc05dlP9nW8sEgr*A*LzJiiKiFpUJPmeOuqzQdsFd.GoVRDaQ6rFrbRG.nM3d7NLRxHQuEmNw0igQuI!/b&bo=DwMDAQAAAAADByw!&rf=viewer_4)

#### 13.10.3 风格代价函数

如果将 $S$ 和 $G$ 代入到风格代价函数中去计算将得到这两个矩阵之间的误差，实际上是计算两个矩阵对应元素相减的平方的和，由于 $G^{[l][S]}$ 和 $G^{[l][G]}$ 是矩阵，故加下标表 Frobenius 范数：
$$
J^{[l]}_{style}(S,G)=||G^{[l][S]}-G^{[l][G]}||^2_F
$$
把这个式子展开，从 $k$ 和 $k′$ 开始作差，然后把得到的结果都加起来，即得到对 $l$ 层定义的风格代价函数：
$$
J^{[l]}_{style}(S,G)=\frac {1}{(2n_H^{[l]}n_W^{[l]}n_c^{[l]})^2} \sum_k \sum_{k'}(G^{[l](S)}_{kk'}-G^{[l](G)}_{kk'})^2
$$
其中，使用了一个归一化常数$\frac {1}{(2n_H^{[l]}n_W^{[l]}n_c^{[l]})^2}$ ，但是一般情况下不用写这么多，只要将风格代价函数乘以一个超参数 $\beta$ 就行。

实际上，如果对各层都使用风格代价函数，会让结果变得更好。如果要对各层都使用风格代价函数，把各个层的结果（各层的风格代价函数）都加起来，就能定义它们全体了：
$$
J_{style}(S,G)=\sum_l \lambda^{[l]}J^{[l]}_{style}(S,G)
$$
其中，需要对每个层定义权重，用 $\lambda^{[l]}$ 来表示，这样将能够在神经网络中使用不同的层，包括之前的一些可以测量类似边缘这样的低级特征的层以及之后的一些能测量高级特征的层，使得我们的神经网络在计算风格时能够同时考虑到这些低级和高级特征的相关系数。这样，在基础的训练中定义超参数时，可以尽可能地得到更合理的选择。

为了把这些东西封装起来，现在定义全体代价函数：
$$
J(G)=αJ_{content}(C,G)+βJ_{style}(S,G)
$$
之后用梯度下降法，或者更复杂的优化算法来找到一个合适的图像 $G$，并计算 $J(G)$ 的最小值，从而将能够得到非常好看漂亮的结果。

#### 13.10.4 用GAN做风格迁移

GAN是解决风格迁移的深度学习方法。

GAN由生成网络G和对抗网络D组成，G用于接收一个噪声z，从而生成图片G(z)；D是一个判别网络，判别一张图片x是不是“真的”我们所需得到的目的图片或者是由G生成的（此时图片是“假的”），即D(x)。
生成网络G和对抗网络D在训练时候互为动态的博弈过程。
损失函数：

![](https://img-blog.csdn.net/20180701175524912?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpb25neGlvbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70) 

其中，x为真实图片，z表示输入G的随机噪声。
GAN之所以能产生对抗博弈的训练过程和效果是因为GAN把训练过程分为了两个部分：

优化D：
![](https://img-blog.csdn.net/20180701175801887?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpb25neGlvbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

优化G:  

![](https://img-blog.csdn.net/20180701175819102?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpb25neGlvbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

将D和G用CNN来表达就是适用于图像处理的DCGAN了。
更多方法详见“https://blog.csdn.net/liongxiong/article/details/80875885”。

### 13.11 一维到三维的推广

#### 13.11.1 2D卷积

假设输入图像为14×14的2维图像，使用5×5的2维过滤器进行卷积，得到 10×10的二维图像，如下图所示：
![](http://m.qpic.cn/psc?/V50v5bPV1er4BO1DcJVb3iyeFd3aL3dx/ruAMsa53pVQWN7FLK88i5rg7mx9bCsYu.AlPVYB8hiF1EPO7cenbSrfhGTxjb0QFu3z44IIucwyOx6zcY2kyV6bpuhw3cgxocglFQVbt*Zc!/b&bo=twKvAAAAAAADBzg!&rf=viewer_4)

#### 13.11.2 1D卷积

举个例子，下图左边是一个EKG信号（心电图），当在胸部放一个电极，电极透过胸部测量心脏带来的微弱电流，每个峰值对应一次心跳。如果想用EKG信号，就需要处理1维数据。因为EKG信号由时间序列对应的每个瞬间的电压组成，是一维的，输入的尺寸是14而不是14×14，就需要用一维过滤进行卷积如一个5的过滤器，而不是5×5。最终的输出尺寸是10。
![](http://m.qpic.cn/psc?/V50v5bPV1er4BO1DcJVb3iyeFd3aL3dx/ruAMsa53pVQWN7FLK88i5m7068PeD46ir41i0jrgOoI8DFni5bneWnmAfdviCBgnaEVc2shxTfCgVYe7on1EcA67udmlufU7OitKyLHVdbM!/b&bo=cQGRAAAAAAADB8M!&rf=viewer_4)

#### 13.11.3 3D卷积

![](http://m.qpic.cn/psc?/V50v5bPV1er4BO1DcJVb3iyeFd3aL3dx/ruAMsa53pVQWN7FLK88i5kKXDpFHQDzWwpqkAaYys4Q71mrmTPj9aGacXGj20tszSGnYAkSk4oL2H5hl0mAUMMPL0aBlffNcP.TNKyXkYn4!/b&bo=1wB8AAAAAAADB4k!&rf=viewer_4)
如上图所示，假设现在输入是具有长度、宽度和高度的三维数据，例如14×14×14，使用5×5×5的过滤器进行卷积，输出将为10×10×10。某种程度上3D数据也可以使用3D confident学习。过滤器实现的功能是用输入的3D数据进行特征识别。

医疗检查是3D卷积的一个实例，如下图所示的CT扫描，用X光输出身体的3D模型：

![](http://m.qpic.cn/psc?/V50v5bPV1er4BO1DcJVb3iyeFd3aL3dx/ruAMsa53pVQWN7FLK88i5rEX3dQ9FgSlnvKQ5qZlshf9hFSB*EhuHZHp*hDdduc7dcnGOI5nPhlZkJ3Uwlj8y6*DNgDKQC03uUmnKMj91WM!/b&bo=GQEYAQAAAAADByM!&rf=viewer_4)