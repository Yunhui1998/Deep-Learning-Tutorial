## 9 机器学习（ML）策略（2）

### 9.1误差分析

#### 9.1.1 定义

​		你希望让学习算法能够胜任人类能做的任务，但你的学习算法还没有达到人类的表现，那么人工检查一下你的算法犯的错误也许可以让你了解接下来应该做什么。**这个过程称为错误分误差**。

​		通过对一组错误样本进行逐一检查后，分析错误样本的类型的比例，来决定朝着哪个方向来进行优化，或者给你构思新优化方向的灵感。



#### 9.1.2 举例

​		假设你正在调试猫分类器，注意到一些算法分类出错的例子中，算法将一些狗分类为猫，为了解决的这个问题，我们不需要，去设计一些只处理狗的算法功能之类的，为了让你的猫分类器在狗图上做的更好，让算法不再将狗分类成猫，因为这花费的时间太长了。而是需要进行误差分析，以便于决定哪一个方向值得努力。

​		首先，比如收集100个错误标记的开发集样本，然后手动检查，一次只看一个，看看你的开发集里有多少错误标记的样本是狗。假设100个错误标记样本中只有5%是狗这意味着100个样本，在典型的100个出错样本中，即使你完全解决了狗的问题，你也只能修正这100个错误中的5个，也就是最多只能将错误率从10%下降到9.5%，效果并不明显。但假设100个错误标记的开发集样本，你发现实际有50张图都是狗，也就是有50%都是狗的照片，现在花时间去解决狗的问题可能效果就很好，错误率可能就从10%下降到5%。



#### 9.1.3 利用表格进行误差分析

​		当然在进行误差分析时，也可以对多个情况或者想法进行评估（比如对狗的照片错认为猫和对狮子的照片错认为猫）。有效且清晰的做法是设计一个表格来对各种错误样本进行填表式的分类，最后统计错误类型的百分比，再针对各种错误类型百分比的大小，进而决定优化的方向，同时最好在每个样本的后面增加备注，以方便进行分析。

![image-20200923101542131](C:\Users\Samzi\AppData\Roaming\Typora\typora-user-images\image-20200923101542131.png)

​		当然，在分类的过程中，如果发现了新的错误类型，也可以直接创建一个新的错误类型





### 9.2 清除标注错误的数据

​		错误的数据：结果的标签是错的。比如猫的图片被标注为不是猫。

#### 9.2.1 处理标签错误的数据

1.对于总数据集总足够大，实际错误率不高的情况下：有时候放着不管也可以，并不会对训练出来的结果有太大的影响

2.对于系统性的错误：需要进行修改

（实际错误率高，比如一直把白色的狗标记成猫，分类器学习之后，会把所有白色的狗都分类为猫）



​		总的来说，在进行误差分析后如果这些标记错误严重影响了你在开发集上评估算法的能力，那么就应该去花时间修正错误的标签。但是，如果它们没有严重影响到你用开发集评估成本偏差的能力，那么可能就不应该花宝贵的时间去处理。



#### 9.2.2 分析错误数据的指标

​		关注整体的开发集错误率、错误标记引起的错误的数量或者百分比，最后根据标记错误引发的错误占总体总体错误率的比例来决定。（简单点说就是标记错误占所有错误的百分比的大小，该百分比越大，说明越值得修改错误标签）

​		比如，系统达到了90%整体准确度，所以有10%错误率，那么你应该看看错误标记引起的错误的数量或者百分比。所以在这种情况下，6％的错误来自标记出错，所以10%的6%就是0.6%。也许你应该看看其他原因导致的错误，如果你的开发集上有10%错误，其中0.6%是因为标记出错，剩下的占9.4%，是其他原因导致的。这个时候更应该考虑对9.4%进行优化或者修正。

​		假设你把错误率降到了2%，但总体错误中的0.6%还是标记出错导致的，此时错误标签导致的错误占总体错误的30%，那么这种情况就值得进行错误标签的修正。



#### 9.2.3 修正标签的原则

1.修正标签时，都要同时作用到验证集和测试集上，也就是必须同时检查验证集和测试集，因为验证和测试集必须来自相同的分布。

2.要考虑同时检验算法判断正确和判断错误的样本，因为如果你只修正算法出错的样本，你对算法的偏差估计可能会变大，这会让你的算法有一点不公平的优势。

3.修正训练集中的标签其实相对没那么重要。



第二点不常遵循，因为一般判断正确的样本所占的比重要大得多。



### 9.3 快速搭建你的第一个系统

​		一般来说，对于几乎所有的机器学习程序可能会有50个不同的方向可以前进，并且每个方向都是相对合理的可以改善你的系统。所以快速设立开发集和测试集还有指标，能够确定系统迭代的方向，并且及时利用训练集对机器学习系统进行训练，再根据结果进行分析来确定下一步优先做什么。



​		下面以建立一个语音识别系统为例子介绍：

​		你可以选择很多不同的技术，让你听写下来的文本可读性更强，所以你可以做很多事情来改进语音识别系统。但对于多种方法你会感到非常迷茫，但当你建立第一个系统后，就能够进行误差分析让你了解到大部分的错误的来源是什么，比如说话人远离麦克风，那么你就有很好的理由去集中精力研究这些技术，也就是确定了你努力的方向





### 9.4 在不同的划分下进行训练并测试

#### 9.4.1 划分的定义

​		划分即在选择数据进行训练时，将不是来自同一分布的数据进行分开，并分别作为数据集的训练集，以及数据集中的验证集和测试集（验证集和测试集得保证来自同分布）。

​		注：在视频中，字幕将dev set翻译为开发集，而以往的笔记中使用的命名为验证集，这里我使用验证集

#### 9.4.2 为什么需要进行划分

​		进行划分的目的在于设定模型的优化方向，也就是“靶心”，通过将需要应用时的数据作为测试集和验证集来进行训练，保证在该模型投入应用时能够有较高的识别率。

​		eg.在识别猫的图片的模型当中，可能会出现拥有充足且清晰的猫的图片进行模型的训练，而对于用户使用这个模型时，可能会使用模糊的照片，而专注于识别清晰照片的模型就较大的概率出现错误。并且这些模糊的照片在刚投入使用的时相较于训练模型时的清晰照片的数量少的多，如训练时清晰的照片可能有20w张，而用户的照片可能只有1w张，并不足以进行训练。

​		如果将清晰的照片和模糊的照片随机分布于数据集当中进行训练，则在期望上清晰的照片在测试集和验证集中的占比就会远大于模糊照片的比例，这就会导致在多次训练中，模型更加偏向于朝着清晰图片的识别的方向进行优化，而不是对用户上传的模糊照片的识别进行优化。

​		如果将模糊和清晰的照片进行划分，将清晰的图片作为训练集，并且将用户模糊的照片作为测试集和验证集，即把模型的优化方向设定为对用户上传的照片的识别，进而不断的提高对用户上传的照片的识别准确率。

​		

### 9.5 不匹配数据划分上的偏差和方差

方差和偏差定义：第二门课第一周笔记

#### 9.5.1 不匹配数据划分对方差和偏差的影响

​		以猫的识别为例，对猫的识别的最优误差几乎为0%，而如果训练集和验证集的数据并不是来自同一分布，如训练集是清晰的照片而测试集是模糊的照片，则训练集的照片容易识别，训练误差小，而验证集的照片难以识别，验证误差大，此时我们不能通过这两个误差值来判断该神经网络的方差是否真的偏大或者偏小，也就是两者的大小区别到底是训练集的数据造成的（也就是方差的问题），还是由于数据来自不同的分布而导致的（也就是数据不匹配问题）（或者两者哪个的影响更大）

#### 9.5.2 训练-验证集（Training-dev set)

​		定义：为了解决在不匹配数据的情况下（也就是上述情况）对方差的判断，我们随机从训练集中抽取一组数据来作为新的子集，也就是训练-验证集。（此时数据集就被分为了四个部分：训练集、训练-验证集、验证集和测试集）

<img src="C:\Users\Samzi\AppData\Roaming\Typora\typora-user-images\image-20200910215916591.png" alt="image-20200910215916591" style="zoom:80%;" />

​		特点：训练-验证集和训练集来自同一分布，验证集和测试集来自同一分布。

​				训练-验证集并不参加训练集对模型的训练，而是和验证集参加反向传播。

​				训练-验证集同时也会进行误差计算，叫做训练-验证集上的误差。

#### 9.5.3 不匹配数据划分下偏差、方差的判断

​		在引入训练-验证集之后，我们通过对训练-验证集的误差值和训练误差以及验证误差三者相结合进行判断，进而得出方差大小或者不同分布对结果影响的结论，当训练误差和训练-验证集误差相差较大时，说明方差较大，当训练-验证集误差和验证误差相差较大时，说明不同分布对结果影响较大，下面将用例子的形式进行判断。

​		对于偏差问题，仍然可以按照以前的方法进行判断。

​		不同分布对结果影响和方差较大问题是可以同时存在的。

（1）训练误差：1%		训练-验证集误差：9%		验证误差：10%

​		训练误差和训练-验证集误差相差较大，方差较大，训练-验证集误差和验证误差相差较小，不同分布对结果影响较小。

（2）训练误差：1%		训练-验证集误差：1.5%		验证误差：10%

​		训练误差和训练-验证集误差相差较小，方差较小，训练-验证集误差和验证误差相差较大，不同分布对结果影响较大。

（3）训练误差：10%		训练-验证集误差：11%		验证误差：20%

​		训练误差和训练-验证集误差相差较大，方差较大，训练-验证集误差和验证误差相差较大，不同分布对结果影响较大。

（4）训练误差：7%		训练-验证集误差：10%		验证误差：6%

​		出现这种和前三种都不同的情况说明，验证集的识别比训练集和训练-验证集这同一分布的数据的识别更加容易。

​		

**对方差，偏差，数据不匹配和过拟合的判断的总结：**

（1）偏差：通过比较最优误差（人类判断误差）和训练误差大小来判断，两者相差越大，偏差越大。

（2）方差：通过比较训练-验证集误差和训练误差大小来判断，两者相差越大，方差越大。

（3）数据不匹配：通过比较训练-验证集误差和验证误差大小来判断，两者相差越大，数据越不匹配。

（4）过拟合：通过比较验证误差和测试误差大小来判断，两者相差越大，模型就越过拟合。



对于降低方差和偏差的方法在第二门课第一周笔记有具体的讲解。









### 9.6 处理数据不匹配问题

**数据不匹配问题**：训练集和开发/测试集来自不同的分布。

#### 9.6.1 处理方法

- 做错误分析，尝试了解训练集和开发/测试集的具体差异（比如有无噪音）。为避免对测试集过拟合，应该人工看开发集而不是测试集。
- 把训练数据变得更像开发集（如人工数据合成），或收集更多类似你的开发集和测试集的数据。

**人工数据合成**：

​		通过对不同类型的数据进行合成，产生需要使用的目的数据。

​		同时人工数据合成也存在问题，在合成数据时，如果选择某类数据时只使用了一小部分进行合成，也就是这类数据类型的子集，从整体的角度来看，这个子集的数据作为样本会导致过拟合的情况出现，也就是过于拟合这个子集数据的特点。而对于这个子集外的同类数据识别效果差。

- 举例一：

![](https://upload-images.jianshu.io/upload_images/24408091-e4c5ebb9e3f9b8e0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

​		建立**语音识别系统**时，在需要解决汽车噪音问题情况，没有那么多实际再汽车背景噪音下录得的音频。这是可以人工合成数据。假设录制了大量清晰的音频，不带车辆背景噪音的音频后，你可以收集一段这样的汽车噪音。然后将两个音频片段放到一起，就可以合成出带有汽车噪声的语音音频。这是一个相对简单的音频合成例子。在实践中，你可能会合成其他音频效果，比如混响，就是声音从汽车内壁上反弹叠加的效果。

​		通过人工数据合成，你可以快速制造更多的训练数据，就像真的在车里录的那样，那就不需要花时间实际出去收集数据，比如说在实际行驶中的车子，录下上万小时的音频。所以，如果错误分析显示你应该尝试让你的数据听起来更像在车里录的，那么人工合成那种音频，然后喂给你的机器学习算法。

**潜在问题**：

​		比如说，你在安静的背景里录得10,000 小时音频数据，然后，比如说，你只录了一小时车辆背景噪音，那么，你可以这么做，将这 1 小时汽车噪音回放 10,000 次，并叠加到在安静的背景下录得的 10,000 小时数据。如果你这么做了，人听起来这个音频没什么问题。但是有可能你的学习算法对这1 小时汽车噪音过拟合。

- 举例二：

![](https://upload-images.jianshu.io/upload_images/24408091-913ce4e9c11f524f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

​		假设你在研发无人驾驶汽车，你可能希望检测出这样的车，然后用框包住它，可以用计算机合成图像来模拟成千上万的车辆。

**潜在问题：**

​		如果你只合成这些车中很小的子集，对于人眼来说也许这样合成图像没什么问题，但你的学习算法可能会对合成的这一个小子集过拟合。特别是很多人都独立提出了一个想法，一旦你找到一个电脑游戏，里面车辆渲染的画面很逼真，那么就可以截图，得到数量巨大的汽车图片数据集。事实证明，如果你仔细观察一个视频游戏，如果这个游戏只有 20 辆独立的车。因为你是在游戏里开车，你只看到这 20 辆车，这个模拟看起来相当逼真。但现实世界里车辆的设计可不只 20 种，如果你用着 20 量独特的车合成的照片去训练系统，那么你的神经网络很可能对这 20 辆车过拟合，但人类很难分辨出来。即使这些图像看起来很逼真，你可能真的只用了所有可能出现的车辆的很小的子集。

- 故使用人工数据合成时，一定要谨慎，要记住你有可能从所有可能性的空间只选了很小一部分去模拟数据。

  

### 9.7 迁移学习

#### **9.7.1 定义**

​		将一个问题上训练好的模型通过简单的调整使其适用于一个新的问题。

#### **9.7.2 举例一**

​		假设你已经训练好一个图像识别神经网络，所以你首先用一个神经网络，并在$(𝑥, 𝑦)$对上训练，其中$𝑥$是图像，$𝑦$是某些对象的判断，图像是猫、狗、鸟或其他东西。如果你把这个神经网络拿来，然后让它适应或者说迁移，在不同任务中学到的知识，比如放射科诊断，就是说阅读𝑋射线扫描图。你可以做的是把神经网络最后的输出层拿走，就把它删掉，还有进入到最后一层的权重删掉，然后为最后一层重新赋予随机权重，然后让它在放射诊断数据上训练。

![](https://upload-images.jianshu.io/upload_images/24408091-0b43c52098c10ed6.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

​		具体来说，在第一阶段训练过程中，当你进行图像识别任务时时，你可以训练神经网络的所有常用参数，所有的权重，所有的层，然后你就得到了一个能够做图像识别预测的网络。在训练了这个神经网络后，要实现迁移学习，你现在要做的是，把数据集换成新的$(𝑥, 𝑦)$对，现在这些变成放射科图像，而$𝑦$是你想要预测的诊断，你要做的是初始化最后一层的权重，让我们称之为$w^{[L]}$和$b^{[L]}$随机初始化。

​		如果你重新训练神经网络中的所有参数，那么这个在图像识别数据的初期训练阶段，有时称为**预训练**（pre -training），因为你在用图像识别数据去预先初始化，或者预训练神经网络的权重。然后，如果你以后更新所有权重，然后在放射科数据上训练，有时这个过程叫**微调**（fine tuning）

#### **9.7.3 举例二**

![](https://upload-images.jianshu.io/upload_images/24408091-2b45ea875c442242.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

​		假设你已经训练出一个语音识别系统，现在$𝑥$是音频或音频片段输入，而$𝑦$是听写文本，所以你已经训练了语音识别系统，让它输出听写文本。现在我们说你想搭建一个“唤醒词”或“触发词”检测系统，所谓唤醒词或触发词就是我们说的一句话，可以唤醒家里的语音控制设备，比如你说“Alexa”可以唤醒一个亚马逊 Echo设备,或用“OK Google”来唤醒 Google 设备，用"Hey Siri"来唤醒苹果设备，用"你好百度"唤醒一个百度设备。要做到这点，你可能需要去掉神经网络的最后一层，然后加入新的输出节点，但有时你可以不只加入一个新节点，或者甚至往你的神经网络加入几个新层，然后把唤醒词检测问题的标签$𝑦$喂进去训练。再次，这取决于你有多少数据，你可能只需要重新训练网络的新层，也许你需要重新训练神经网络中更多的层。

#### **9.7.4 迁移学习有效的原因**

​		在例一中我们把图像识别中学到的知识应用或迁移到放射科诊断上来。有很多低层次特征，比如说边缘检测、曲线检测、阳性对象检测，**从非常大的图像识别数据库中习得这些能力可能有助于你的学习算法在放射科诊断中做得更好**，算法学到了很多结构信息，图像形状的信息，其中一些知识可能会很用，所以学会了图像识别，它就可能学到足够多的信息，可以了解不同图像的组成部分是怎样的，学到线条、点、曲线这些知识，也许对象的一小部分，这些知识有可能帮助你的放射科诊断网络学习更快一些，或者需要更少的学习数据。

​		对于第二个例子语音识别，也许你已经用 10,000 小时数据训练过你的语言识别系统，所以你从这10,000 小时数据学到了很多人类声音的特征，这数据量其实很多了。但对于触发字检测，也许你只有 1 小时数据，所以这数据太小，不能用来拟合很多参数。所以在这种情况下，预先学到很多人类声音的特征人类语言的组成部分等等知识，可以帮你建立一个很好的唤醒字检测器，即使你的数据集相对较小。

#### **9.7.5 迁移学习起作用的场合**

​		1.以任务A迁移到任务B为例，任务A和任务B都有同样的输入x时,如输入都是图片

​		2.任务A的数据比任务B的多得多，任务A的数据才会对B有帮助。

​		3.任务A的低层次特征可以帮助B的学习

​		如果你尝试优化任务𝐵的性能，通常这个任务数据相对较少，例如，在放射科中你知道很难收集很多𝑋射线扫描图来搭建一个性能良好的放射科诊断系统，所以在这种情况下，你可能会找一个相关但不同的任务，如图像识别，其中你可能用 1 百万张图片训练过了，并从中学到很多低层次特征，所以那也许能帮助网络在任务𝐵在放射科任务上做得更好，尽管任务𝐵没有这么多数据。



### 9.8 多任务学习

#### **9.8.1 定义**

​		让单个神经网络同时做几个任务，并且这里每个任务都能帮到其他所有任务。

#### **9.8.2 举例**

​		假设你在研发无人驾驶车辆，那么你的无人驾驶车可能需要同时检测不同的物体，比如检测行人、车辆、停车标志，还有交通灯各种其他东西。

​		如果这是输入图像$𝑥^{(𝑖)}$，那么这里不再是一个标签 $y^{(𝑖)}$，而是有 4 个标签。在这个例子中，没有行人，有一辆车，有一个停车标志，没有交通灯。然后如果你尝试检测其他物体，也许 $y^{(𝑖)}$的维数会更高，现在我们就先用 4 个，所以 $y^{(𝑖)}$是个 4×1 向量。如果你从整体来看这个训练集标签和以前类似，我们将训练集的标签水平堆叠起来，像这样$y^{(1)}$一直到$y^{(m)}$： 
$$
Y=\left[\begin{array}{ccccc}| & | & | & \ldots & | \\ y^{(1)} & y^{(2)} & y^{(3)} & \ldots & y^{(m)} \\ | & | & | & \ldots & |\end{array}\right]
$$
​		不过现在$y^{(𝑖)}$是 4×1 向量，所以这些都是竖向的列向量，所以这个矩阵$𝑌$现在变成4 × 𝑚矩阵。而之前，当$𝑦$是单实数时，这就是1 × 𝑚矩阵。

![](https://upload-images.jianshu.io/upload_images/24408091-c85a642c1b6d5686.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

​		训练一个神经网络，来预测这些𝑦值，你就得到这样的神经网络，输入$𝑥$，现在输出是一个四维向量$𝑦$。请注意，这里输出我画了四个节点，所以第一个节点就是我们想预测图中有没有行人，然后第二个输出节点预测的是有没有车，第三个节点预测有没有停车标志，第四个节点预测有没有交通灯，所以这里$\hat{y}$是四维的。

​		要训练这个神经网络，你现在需要定义神经网络的损失函数，对于一个输出$\hat{y}$，是个4维向量，对于整个训练集的平均损失：
$$
\frac{1}{m} \sum_{i=1}^{m} \sum_{j=1}^{4} L\left(\hat{y}_{j}^{(i)}, y_{j}^{(i)}\right)
$$


$\sum_{j=1}^{4} L\left(\hat{y}_{j}^{(i)}, y_{j}^{(i)}\right)$是单个预测的损失，即对四个分量的求和，行人、车、停车标志、交通灯。$L$指的是logistic损失：
$$
L\left(\hat{y}_{j}^{(i)}, y_{j}^{(i)}\right)=-y_{j}^{(i)} \log \hat{y}_{j}^{(i)}-\left(1-y_{j}^{(i)}\right) \log \left(1-\hat{y}_{j}^{(i)}\right)
$$
​		整个训练集的平均损失和之前分类猫的例子主要区别在于，现在你要对$𝑗 = 1$到$4$求和，这与 **softmax** 回归的主要区别在于，**softmax** 将单个标签分配给单个样本。

​		在这个场合，一张图可以有多个标签。如果你训练了一个神经网络，试图最小化这个成本函数，你做的就是多任务学习。因为你现在做的是建立单个神经网络，观察每张图，然后解决四个问题，系统试图告诉你，每张图里面有没有这四个物体。另外你也可以训练四个不同的神经网络，而不是训练一个网络做四件事情。但**神经网络一些早期特征，在识别不同物体时都会用到**，然后你发现，训练一个神经网络做四件事情会比训练四个完全独立的神经网络分别做四件事性能要更好，这就是多任务学习的力量。

<img src="https://upload-images.jianshu.io/upload_images/24408091-f0a010db6a4f9ae1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%;" />

​		多任务学习也**可以处理图像只有部分物体被标记的情况**。所以第一个训练样本，我们说有人，给数据贴标签的人告诉你里面有一个行人，没有车，但他们没有标记是否有停车标志，或者是否有交通灯。也许第二个例子中，有行人，有车。但是，当标记人看着那张图片时，他们没有加标签，没有标记是否有停车标志，是否有交通灯等等。也许有些样本都有标记，但也许有些样本他们只标记了有没有车，然后还有一些是问号。

​		即使是这样的数据集，你也可以在上面训练算法，同时做四个任务，即使一些图像只有一小部分标签，其他是问号或者不管是什么。然后你训练算法的方式，即使这里有些标签是问号，或者没有标记，这就是对𝑗从 1 到 4 求和，你就只对带 0 和 1 标签的$𝑗$值求和，所以当有问号的时候，你就在求和时忽略那个项，这样只对有标签的值求和，于是你就能利用这样的数据集。

#### **9.8.3 和迁移学习的不同**

​		多任务学习是一种迁移学习的方法，但不同于其他种类的迁移学习，多任务学习并不注重源领域和未知领域的知识迁移，它主要利用域之间相似的知识信息，提升特定任务的学习效果，注重领域知识的共享性。两者特点的不同决定了学习过程的差别，迁移学习的目的是通过从源任务中转移知识来提升目标任务中的性能，而多任务学习则试图同时学习目标任务和源任务。

参考文章：张钰,刘建伟,左信.多任务学习[J].计算机学报,2020,43(07):1340-1378.

#### **9.8.4 多任务学习使用场合**

- **你训练的一组任务，可以共用低层次的特征。**

  ​		对于无人驾驶的例子，同时识别交通灯、汽车和行人是有道理的，这些物体有相似的特征，也许能帮你识别停车标志，因为这些都是道路上的特征。

- **每个任务的数据量很接近。**

  ​		这个准则不一定对。

  ​		在多任务学习中，你通常有更多任务而不仅仅是两个，所以也许你有，以前我们有 4个任务，但比如说你要完成 100 个任务，而你要做多任务学习，尝试同时识别 100 种不同类型的物体。你可能会发现，每个任务大概有 1000 个样本。所以如果你专注加强单个任务的性能，比如我们专注加强第 100 个任务的表现，我们用𝐴100表示，如果你试图单独去做这个最后的任务，你只有 1000 个样本去训练这个任务，这是 100 项任务之一，而通过在其他99 项任务的训练，这些加起来可以一共有 99000 个样本，这可能大幅提升算法性能，可以提供很多知识来增强这个任务的性能。不然对于任务𝐴100，只有 1000 个样本的训练集，效果可能会很差。如果有对称性，这其他 99 个任务，也许能提供一些数据或提供一些知识来帮到这 100 个任务中的每一个任务。

  ​		所以第二点不是绝对正确的准则，但我通常会看的是如果你专注于单项任务，如果想要从多任务学习得到很大性能提升，那么其他任务加起来必须要有比单个任务大得多的数据量。要满足这个条件，其中一种方法是，比如右边这个例子这样，或者如果每个任务中的数据量很相近，但关键在于，如果对于单个任务你已经有 1000个样本了，那么对于所有其他任务，你最好有超过 1000 个样本，这样其他任务的知识才能帮你改善这个任务的性能。

- **当你可以训练一个足够大的神经网络，同时做好所有工作。**

  ​		多任务学习的替代方法是为每个任务训练一个单独的神经网络。所以不是训练单个神经网络同时处理行人、汽车、停车标志和交通灯检测。你可以训练一个用于行人检测的神经网络，一个用于汽车检测的神经网络，一个用于停车标志检测的神经网络和一个用于交通信号灯检测的神经网络。

  ​		多任务学习会降低性能的唯一情况，和训练单个神经网络相比性能更低的情况就是你的神经网络还不够大。但如果你可以训练一个足够大的神经网络，那么多任务学习肯定不会或者很少会降低性能，我们都希望它可以提升性能，比单独训练神经网络来单独完成各个任务性能要更好。



（Life long learning）



### 9.9 什么是端到端的深入学习

#### 9.9.1 端到端学习定义

​		以往对于一次任务可能需要分解成多个阶段的学习(流水线)，端到端的深度学习用单个神经网络替换多个学习过程，只需要把训练集拿过来，直接学到$x$和$y$之间的函数映射，绕过了其中很多步骤。
​		下图以语音识别为例，进行两者间的对比。

![1.JPG](https://upload-images.jianshu.io/upload_images/24435917-c86a4bb30793f28a.JPG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

​		端到端的深入学习需要大量数据，如果数据量较小，以往的流水线可能会好于端到端的深度学习。

#### 9.9.2 端到端学习应用场景

- 例子一：在人脸识别任务中，端到端的深度学习并不能很好的完成任务，而以往的分步识别效果更佳，先识别人脸位置，随后和数据库进行人脸比对，因为分解到两个任务后可以对每个任务进行有效处理。

- 例子二：机器翻译，端到端深度学习在机器翻译领域非常好用，可以收集大量成对的大数据集，如原文句子和对应的翻译。

- 例子三：从手部X射线图估计孩子年龄，拆分任务效果更好，分析知道不同骨骼的长度后，可以查表查到儿童手中骨头的平均长度。而端到端的深度学习并未取得很好的效果，因为没有足够的数据来用端到端的方式来训练这个任务。

  


### 9.10 是否要使用端到端学习 

​	当决定是否使用端对端方法时，可以参考端到端深度学习的一些优缺点来进行判断。

#### 9.10.1 端对端方法的优点

1. 可以让数据说话，挖掘客观信息，不用引入人类的成见。

   例如，在语音识别领域，人类学习的音位概念更像是是人类语言学家生造出来的。而学习算法不会强迫以音位为单位思考，它能够学习的任意的表示方式。

2. 需要手工设计的组件很少，也许能够简化设计工作流程。我们只需要把训练集拿过来，直接学到$x$和$y$之间的函数映射，绕过了其中很多步骤。

#### 9.10.2 端对端方法的缺点

1. 需要大量的数据。

   比如人脸识别，需要收集很多数据用来分辨图像中的人脸。但是对于整个端到端任务，可能只有更少的数据可用。

2. 排除了一些可能有用的人工组件。因为直接从系统的一端学习到系统的另一端，舍弃了人类对这个问题的很多认识。

   比如，把手的X射线照片直接映射到孩子的年龄，可能需要很复杂的函数，如果用纯端到端方法，也需要大量数据去学习。

   **可以看出，决定是否要使用端到端深度学习的主要因素是是否有足够的数据来训练。**复杂问题有时候并不适合端到端，人类的意见还是很有必要的，手工设计的组件往往在训练集更小的时候帮助更大。