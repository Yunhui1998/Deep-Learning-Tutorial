## 10 卷积神经网络

### 10.1 计算机视觉

计算机视觉（Computer Vision）是指用计算机实现人的视觉功能——对客观世界的三维场景的感知、识别和理解。它的任务包括：

1. 图片分类（图片识别）：识别图像物体属于的类别。比如分辨图片中的猫咪。

2. 目标检测：用框去标出物体的位置，并给出物体的类别。比如无人驾驶项目中，识别图片中障碍物的位置，再将它们模拟成一个个盒子，并计算距离。

3. 风格迁移：如图1所示，两种不同的图片风格，可以利用神经网络将它们融合到一起，描绘出一张新的图片。它的整体轮廓来自于左边，却是右边的风格。

![1.png](https://upload-images.jianshu.io/upload_images/24435917-426ff4bbcd67093c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

<center>图1</center>

4. 图像语义分割：像素级分类，输出图像与输入图像大小一致，整体效果为图像的每一个区域都会分类。如图

   ![headrende0000.png](https://upload-images.jianshu.io/upload_images/16793245-04a888f877495dd5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

   ![headrende0001.png](https://upload-images.jianshu.io/upload_images/16793245-566d5b15c851e98e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

为何难以使用全连接？

图片处理的数据量巨大。如果是1000x1000的彩色图片，因为每张图片都有3个颜色通道，那么输入就是300万，进入神经网络后假设第一层有1000个节点，那么$w_1$的参数个数就是30亿，如此大的参数量对内存和计算资源都是一种挑战，面对这个问题需要使用计算机视觉中常用的卷积操作。 




### 10.2 边缘检测

#### 10.2.1 卷积神经网络中的卷积运算

以一维灰度图像为例，输入是6×6×1的矩阵，构造一个3×3×1的矩阵，如图2所示。在卷积神经网络的术语中，它被称为过滤器（又称卷积核）。

对输入矩阵进行卷积，即输入矩阵与卷积核相乘，具体乘法方式为：从输入矩阵左上角开始找到与卷积核相同尺寸的小矩阵，并对应位置相乘求和，得到第一个卷积的结果，继续位移对整个矩阵进行该操作，得到新的矩阵，过程如下：

![z2.png](https://upload-images.jianshu.io/upload_images/24435917-5f5372d58240fe6d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

<center>图2</center>

1. 计算输出矩阵第一个元素：对于4×4输出矩阵最左上角元素，使用3×3的过滤器，将其覆盖在输入图像，如图2所示。然后进行元素乘法运算，即：

$$
\left[\begin{array}{ccc}
3 \times 1 & 0 \times 0 & 1 \times(1) \\
1 \times 1 & 5 \times 0 & 8 \times(-1) \\
2 \times 1 & 7 \times 0 & 2 \times(-1)
\end{array}\right]=\left[\begin{array}{ccc}
3 & 0 & -1 \\
1 & 0 & -8 \\
2 & 0 & -2
\end{array}\right]
$$

然后将该矩阵每个元素相加得到最左上角的元素，即3 + 1 + 2 + 0 + 0 + 0 + (-1) + (-8) + (-2) = -5。

2. 计算输出矩阵第二个元素：即图3标注的红框，先把蓝色的方块向右移动一步，再继续做同样的元素乘法，然后相加，所以是0×1 + 5×1 + 7×1 + 1×0 + 8×0 + 2×0 + 2×(-1) + 9×(-1) + 5×(-1) = -4。以此类推，可以计算输出矩阵第一行的值。

![2.png](https://upload-images.jianshu.io/upload_images/24435917-28b6f46c39785804.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

<center>图3</center>

3. 得到下一行的元素：把蓝色块下移，到如图4所示位置，重复进行元素乘法，然后加起来。通过这样做得到-10。再将其右移得到-2，接着是2，3。以此类推，这样计算完矩阵中的其他元素。

![3.png](https://upload-images.jianshu.io/upload_images/24435917-7ddbe9c79aa9b2b8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

<center>图3</center>

左边矩阵容易被理解为一张图片，中间的这个被理解为过滤器，右边的图片可以理解为另一张图片。这就是垂直边缘检测器。结果如图所示：

![0.png](https://upload-images.jianshu.io/upload_images/24435917-541532af164227b3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

<center>图4</center>

#### 10.2.2 垂直边缘检测

为了讲清楚，举一个简单的例子。这是一个简单的6×6图像，左边的一半是10，代表亮色，右边一半是0，代表暗色。在中间部分，就被视为一个垂直边缘。

使用一个3×3过滤器进行卷积运算，得到图5最右边4×4的输出矩阵，在中间有段亮一点的区域（30），即对应检查到6×6图像中间的垂直边缘。结果为正数（30），代表从左至右来看，原图左半部分较亮。
![4.png](https://upload-images.jianshu.io/upload_images/24435917-9a714258def0d989.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

<center>图5</center>

#### 10.2.3 水平边缘检测

相似的，如图六所示，检测输入图片的水平边缘，左上方和右下方都相对较亮（10）。水平边缘过滤器则是一个3×3的矩阵，但是它的上边相对较亮（1），而下方相对较暗（-1）。

卷积后从输出矩阵看出一条水平边缘。其中左半部分为正数（30，10），代表从上至下来看，原图上面部分较亮。右半部分为负数（-10，-30），代表原图下面部分较亮。

![6.png](https://upload-images.jianshu.io/upload_images/24435917-6e0641876fa7a3b8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

<center>图6</center>

#### 10.2.4 区分正边和负边

假如把输入图片的颜色翻转，变成了左边比较暗，而右边比较亮，使用相同的过滤器进行卷积，最后得到的图中间会是-30，而不是30。表明是由暗向亮过渡，而不是由亮向暗过渡。因此，输出的正负即可代表边缘的过渡情况。
![5.JPG](https://upload-images.jianshu.io/upload_images/24435917-32c535a830f6011a.JPG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

<center>图7</center>

#### 10.2.5 为什么是3*3的卷积核？

1. 3x3是最小的能够捕获像素八邻域信息的尺寸。
2. 两个3x3的卷积核有限感受野是5x5；三个3x3的卷积核的感受野是7x7，故可以通过小尺寸卷积层的堆叠替代大尺寸卷积层，并且感受野大小不变。
3. 多个3x3的卷积核比一个大尺寸卷积核有更多的非线性（更多层可以使用更多个非线性函数）。
4. 多个3x3的卷积层比一个大尺寸卷积核有更少的参数，如三个3x3的卷积层参数个数3x3x3=27；一个7x7的卷积层参数为49。唯一的不足是，在进行反向传播时，中间的卷积层可能会导致占用更多的内存。


### 10.3 更多的边缘检测

在历史上，在计算机视觉的文献中，对于这个3×3的过滤器来说，曾公平地争论过怎样的数字组合才是最好的。不同的过滤器可以起到不同的效果，如Sobel过滤器，Scharr过滤器。

1. Prewitt过滤器：是一种图像边缘检测的微分算子，其原理是利用特定区域内像素灰度值产生的差分实现边缘检测。实际上也是一种垂直边缘检测。将其翻转90度，就能得到对应水平边缘检测。

$$
\left[\begin{array}{lll}-1 & 0 & 1 \\-1 & 0 & 1 \\-1 & 0 & 1\end{array}\right]
$$


2. Sobel的过滤器：它的优点在于增加了中间一行元素的权重，这使得结果的鲁棒性会更高一些。

$$
\left[\begin{array}{lll}
1 & 0 & -1 \\
2 & 0 & -2 \\
1 & 0 & -1
\end{array}\right]
$$

3. Scharr过滤器：它和sobel过滤器类似，但结果更为精确。

$$
\left[\begin{array}{lll}
3 & 0 & -3 \\
10 & 0 & -10 \\
3 & 0 & -3
\end{array}\right]
$$

4. 拉普拉斯(Laplacian) 过滤器：是 $n$ 维欧几里德空间中的一个二阶微分算子，常用于图像增强领域和边缘提取。它可以判断中心像素灰度与邻域内其他像素灰度的关系。Laplacian算子分为四邻域和八邻域，四邻域是对邻域中心像素的四个方向求梯度，八邻域是对八个方向求梯度。
   其中，Laplacian算子四邻域模板如下所示：

$$
\begin{array}{l}
\mathrm{H}=\left[\begin{array}{ccc}
0 & -1 & 0 \\
-1 & 4 & -1 \\
0 & -1 & 0
\end{array}\right] \\
\end{array}
$$

八邻域模板如下所示：
$$
\begin{array}{l}
\mathrm{H}=\left[\begin{array}{ccc}
-1 & -1 & -1 \\
-1 & 8 & -1 \\
-1 & -1 & -1
\end{array}\right]
\end{array}
$$

5. Kirsch过滤器：类似于Sobel过滤器，Sobel过滤器计算出某点两个方向的梯度值$G_x$、$G_y$；但Kirsch过滤器利用8个卷积模板来确定梯度幅度值和梯度的方向，并以最大的卷积值作为该点的灰度值。

![](https://img-blog.csdnimg.cn/20190517110939663.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDQwMzk1Mg==,size_16,color_FFFFFF,t_70)

<center>图8</center>

将过滤器的所有数字都设置为参数，可以通过反向传播学习，得到的滤波器没有特定的名称，但是可以检测不同的特征，如偏向45度的边缘检测，或者70度78度都可以检测。
这种将这9个数字当成参数的思想，已经成为计算机视觉中最为有效的思想之一。

### 10.4 Padding

**为什么需要Padding？**

如果你用一个 3×3 的过滤器卷积一个 6×6 的图像，你最后会得到一个 4×4 的输出，也就是一个 4×4 矩阵。因为你的 3×3 过滤器在 6×6 矩阵中，只可能有 4×4 种可能的位置。这背后的数学解释是，如果我们有一个𝑛 × 𝑛的图像，用𝑓 × 𝑓的过滤器做卷积，那么输出的维度就是(𝑛 − 𝑓 + 1) × (𝑛 − 𝑓 + 1)。在这个例子里是6 − 3 + 1 = 4，因此得到了一个 4×4 的输出。

![](https://upload-images.jianshu.io/upload_images/24408091-11d67e3c9fc98f96.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这样的话会有两个缺点。

第一个缺点是**输出缩小**。每次做卷积操作，图像就会缩小，从 6×6 缩小到 4×4，你可能做了几次之后，你的图像就会变得很小了，可能会缩小到只有 1×1 的大小。但我们不想让图像在每次识别边缘或其他特征时都缩小。

第二个缺点是**丢失了图像边缘的大部分信息**。角落边缘的像素点只被一个输出所触碰或者使用，因为它位于这个 3×3 的区域的一角。但如果是在中间的像素点，就会有许多 3×3 的区域与之重叠。所以那些在角落或者边缘区域的像素点在输出中采用较少，意味着你丢掉了图像边缘位置的许多信息。

为了解决这些问题，我们可以进行Padding操作——在卷积操作之前填充这幅图像。

**Padding**

![](https://upload-images.jianshu.io/upload_images/24408091-a593a124817506f9.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

例如，我们沿着图像边缘再填充一层像素。那么 6×6 的图像就被你填充成了一个 8×8 的图像。如果你用 3×3 的图像对这个 8×8 的图像卷积，你得到的输出就不是 4×4 的，而是 6×6的图像，你就得到了一个尺寸和原始图像 6×6 的图像。习惯上，你可以用 0 去填充。

**使用Padding后计算输出图像的大小**

如果𝑝是填充的数量，输出就变成(𝑛 + 2𝑝 − 𝑓 + 1) × (𝑛 + 2𝑝 − 𝑓 + 1)。

在这个案例中，𝑝 = 1，因为我们在周围都填充了一个像素点，所以就变成了(6 + 2 × 1 − 3 + 1) × (6 + 2 × 1 − 3 + 1) = 6 × 6。

**Valid卷积**

意味着不填充。
$$
(n \times n) \text { * } (f \times f) \rightarrow (n-f+1) \times (n-f+1)
$$
**Same卷积**

意味着填充后输出大小和输入大小是一样的。
$$
(n+2 p) \times (n+2 p) \quad * \quad (f \times f) \rightarrow (n+2 p-f+1 ) \times (n+2 p-f+1)
$$
根据这个公式𝑛 − 𝑓 + 1，当你填充𝑝个像素点，𝑛就变成了𝑛 + 2𝑝，最后公式变为𝑛 + 2𝑝 − 𝑓 + 1。因此如果你有一个𝑛 × 𝑛的图像，用𝑝个像素填充边缘，输出的大小就是这样的(𝑛 + 2𝑝 − 𝑓 + 1) × (𝑛 + 2𝑝 − 𝑓 + 1)。

如果你想让**𝑛 + 2𝑝 − 𝑓 + 1 = 𝑛**的话，使得输出和输入大小相等，如果你用这个等式求解𝑝，那么**𝑝 = (𝑓 − 1)/2**。所以当𝑓是一个奇数的时候，只要选择相应的填充尺寸，你就能确保得到和输入相同尺寸的输出。

习惯上，计算机视觉中，𝑓通常是奇数。如果𝑓是一个偶数，那么你只能使用一些不对称填充。只有𝑓是奇数的情况下，Same 卷积才会有自然的填充，我们可以以同样的数量填充四周，而不是左边填充多一点，右边填充少一点，这样不对称的填充。其次，当你有一个奇数维过滤器，比如 3×3 或者 5×5 的，它就有一个中心点。有时在计算机视觉里，如果有一个中心像素点会更方便，便于指出过滤器的位置。

### 10.5 卷积步长

卷积中的步幅是另一个构建卷积神经网络的基本操作，如下例。

![](https://upload-images.jianshu.io/upload_images/24408091-933e4cf26132fe6e.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

如果你想用 3×3 的过滤器卷积这个 7×7 的图像，和之前不同的是，我们把步幅设置成了2。你还和之前一样取左上方的 3×3 区域的元素的乘积，再加起来，最后结果为 91。

![](https://upload-images.jianshu.io/upload_images/24408091-f55f50fd11c0f93a.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

只是之前我们移动蓝框的步长是 1，现在移动的步长是 2，我们让过滤器跳过 2 个步长，注意一下左上角，这个点移动到其后两格的点，跳过了一个位置。然后你还是将每个元素相乘并求和，你将会得到的结果是 100。

现在我们继续，将蓝色框移动两个步长，你将会得到 83 的结果。当你移动到下一行的时候，你也是使用步长 2 而不是步长 1，所以我们将蓝色框移动到这里：

![](https://upload-images.jianshu.io/upload_images/24408091-e58c347fa2edc130.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

注意到我们跳过了一个位置，得到 69 的结果，现在你继续移动两个步长，会得到 91，127，最后一行分别是 44，72，74。

![](https://upload-images.jianshu.io/upload_images/24408091-8411e8e9648f6e6e.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

在这个例子中，用 3×3 的矩阵卷积一个 7×7 的矩阵，得到一个 3×3 的输出。输入和输出的维度是由下面的公式决定的。

如果你用一个𝑓 × 𝑓的过滤器卷积一个𝑛 × 𝑛的图像，你的 padding为𝑝，步幅为𝑠，在这个例子中𝑠 = 2，你会得到一个输出，因为现在你不是一次移动一个步子，而是一次移动𝑠个步子，输出于是变为
$$
(\frac{n+2 p-f}{s}+1) \times (\frac{n+2 p-f}{s}+1)
$$
如果商不是一个整数，则**向下取整**。

<img src="https://upload-images.jianshu.io/upload_images/24408091-9352d8e6c16c7191.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%;" />

⌊ ⌋这是向下取整的符号，这也叫做对𝑧进行地板除(floor)，这意味着𝑧向下取整到最近的整数。这个原则实现的方式是，你只在蓝框完全包括在图像或填充完的图像内部时，才对它进行运算。如果有任意一个蓝框移动到了外面，那你就不要进行相乘操作，这是一个惯例。

可以选择所有的数使结果是整数是挺不错的，尽管一些时候，你不必这样做，只要向下取整也就可以了。你也可以自己选择一些𝑛，𝑓，𝑝和𝑠的值来验证这个输出尺寸的公式是对的。

**卷积（concolution）与互相关(cross-correlation)**

如果你看的是一本典型的数学教科书，那么卷积的定义是做元素乘积求和，实际上还有一个步骤是你首先要做的，也就是在把这个 6×6 的矩阵和 3×3 的过滤器卷积之前，首先你将 3×3 的过滤器沿水平和垂直轴翻转，所以
$$
\left[\begin{array}{ccc}
3 & 4 & 5 \\
1 & 0 & 2 \\
-1 & 9 & 7
\end{array}\right] \text { 变为 }\left[\begin{array}{ccc}
7 & 2 & 5 \\
9 & 0 & 4 \\
-1 & 1 & 3
\end{array}\right]
$$
这相当于将 3×3 的过滤器做了个**镜像**，在水平和垂直轴上。然后再把这个翻转后的矩阵复制到这里（左边的图像矩阵），你要把这个翻转矩阵的元素相乘来计算输出的 4×4 矩阵左上角的元素，如图所示。然后取这 9 个数字，把它们平移一个位置，再平移一格，以此类推。

<img src="https://upload-images.jianshu.io/upload_images/24408091-3fc95764e3d00301.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom: 50%;" />

但在深度学习文献中，定义卷积运算时跳过了这个镜像操作。前面我们实际上做的，有时被称为互相关而不是卷积。

总结来说，按照机器学习的惯例，我们通常不进行翻转操作。从技术上说，这个操作可能叫做互相关更好。但在大部分的深度学习文献中都把它叫做卷积运算。

### 10.6 三维卷积

**三维（RGB图像）上的卷积操作**

举例，假如你不仅想检测灰度图像的特征，也想检测 RGB 彩色图像的特征。彩色图像如果6×6×3，这里的第一个 6 代表图像高度，第二个 6 代表宽度，这个3 代表颜色通道的数目。你可以把它想象成三个 6×6图像的堆叠。为了检测图像的边缘或者其他的特征，不是把它跟原来的 3×3 的过滤器做卷积，而是跟一个三维的过滤器，它的维度是 3×3×3，这样这个过滤器也有三层，对应红、绿、蓝三个通道。得到的输出会是一个 4×4 的图像，注意是 4×4×1，最后一个数不是 3 了。

为了简化这个 3×3×3过滤器的图像，我们不把它画成 3 个矩阵的堆叠，而画成一个三维的立方体。

![](https://upload-images.jianshu.io/upload_images/24408091-4bcf86d86ff07fe2.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

**计算过程**：

把这个 3×3×3 的过滤器先放到最左上角的位置，这个 3×3×3 的过滤器有 27 个数，27 个参数就是 3 的立方。依次取这 27 个数，然后乘以相应的红绿蓝通道中的数字。先取红色通道的前 9 个数字，然后是绿色通道，然后再是蓝色通道，乘以左边黄色立方体覆盖的对应的 27 个数，然后把这些数都加起来，就得到了输出的第一个数字。如果要计算下一个输出，你把这个立方体滑动一个单位，再与这 27 个数相乘，把它们都加起来，就得到了下一个输出，以此类推。

![](https://upload-images.jianshu.io/upload_images/24408091-1af1dd413ff2f354.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



**作用**：

举例：

- 如果你想检测图像红色通道的边缘，那么你可以将第一个过滤器设为$\left[\begin{array}{rrr}1 & 0 & -1 \\ 1 & 0 & -1 \\ 1 & 0 & -1\end{array}\right]$，和之前一样，而绿色通道全为 0，$\left[\begin{array}{lll}0 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 0\end{array}\right]$，蓝色也全为 0。如果你把这三个堆叠在一起形成一个3×3×3的过滤器，那么这就是一个检测垂直边界的过滤器，但只对红色通道有用。
- 或者如果你不关心垂直边界在哪个颜色通道里，那么你可以用一个这样的过滤器，$\left[\begin{array}{ccc}1 & 0 & -1 \\ 1 & 0 & -1 \\ 1 & 0 & -1\end{array}\right],\left[\begin{array}{ccc}1 & 0 & -1 \\ 1 & 0 & -1 \\ 1 & 0 & -1\end{array}\right],\left[\begin{array}{ccc}1 & 0 & -1 \\ 1 & 0 & -1 \\ 1 & 0 & -1\end{array}\right]$，所有三个通道都是这样。所以通过设置第二个过滤器参数，你就有了一个边界检测器，3×3×3 的边界检测器，用来检测任意颜色通道里的边界。参数的选择不同，可以得到不同的特征检测器，所有的都是 3×3×3 的过滤器。

**同时用多个过滤器**

有时候我们会想要同时检测垂直边缘和水平边缘，还有 45°倾斜的边缘，还有 70°倾斜的边缘等等，这是就需要使用多个过滤器。

![](https://upload-images.jianshu.io/upload_images/24408091-3afde858bde7c86d.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

例如我们让这个 6×6×3 的图像和这个 3×3×3 的过滤器卷积，得到 4×4 的输出。（第一个）这可能是一个垂直边界检测器或者是学习检测其他的特征。第二个过滤器可以用橘色来表示，它可以是一个水平边缘检测器。做完卷积，然后把这两个 4×4 的输出堆叠在一起，这样你就都得到了一个4×4×2 的输出立方体。这里的 2 的来源于我们用了两个不同的过滤器。

**维度总结**

如果你有一个$n \times n \times n_{c}$（通道数）的输入图像，上例中就是 6×6×3，这里的$n_{c}$就是通道数目，然后卷积上一个$f \times f \times n_{c}$，这个例子中是 3×3×3，按照惯例，这个（前一个𝑛𝑐）和这个（后一个𝑛𝑐）必须数值相同。然后你就得到了，$(n-f+1)\times(n-f+1) \times n_{c^{\prime}}$这里$n_{c^{\prime}}$其实就是下一层的通道数，它就是你用的过滤器的个数，在我们的例子中，那就是 4×4×2。我写下这个假设时，用的步幅为 1，并且没有 padding。如果你用了不同的步幅或者 padding，那么这个$𝑛 − 𝑓 + 1$数值会变化。
$$
n \times n \times n_{c} \text { * } f \times f \times n_{c} \rightarrow (n-f+1)\times(n-f+1) \times n_{c^{\prime}}
$$
**思考**：为什么卷积核是3\*3channels而不是3\*3\*1在多个通道之间移动？

如果使用3\*3\*1的卷积核在多个通道中移动，那意味着每个通道都用同一个过滤器，而且每个过滤器（卷积核）都忽略了隐藏在通道之间的联系和信息，这无疑会降低卷积网络的效果。

### 10.7 单层卷积网络

![layer](https://upload-images.jianshu.io/upload_images/16793245-bc6603c28032d8a3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

相比之前的卷积过程，CNN的单层结构多了激活函数ReLU和偏移量b，与神经网络的单层结构类似，即：

​                                         $Z^{[l]}=W^{[l]} A^{[l-1]}+b$
​                                         $A^{[l]}=g^{[l]}\left(Z^{[l]}\right)$

其中，卷积运算对应上式中的乘积运算，过滤器组数值对应着权重$W^{[l]}$,激活函数则为ReLU

上图中参数$W$的计算：每个过滤器组共有3x3x3=27个参数，两个过滤器组则共包含27x2=54个参数$W$

相关符号的总结（设层数为$l$)

​                                                        $f^{[l]}=$ filter size
​                                                        $p^{[l]}=$ padding
​                                                        $s^{[l]}=$ stride
​                                                        $n_{c}^{[l]}=$ number of filters
​                                                        $n_{H}^{[l]}=$ height of input
​                                                        $n_{W}^{[l]}=$ width of filters

输入维度为：

​                                                          $n_{H}^{[l-1]} \times n_{W}^{[l-1]} \times n_{c}^{[l-1]}$
每个滤波器组维度为：

​                                                          $f^{[l]} \times f^{[l]} \times n_{c}^{[l-1]}$

权重维度为： 

​                                                          $f^{[l]} \times f^{[l]} \times n_{c}^{[l-1]} \times n_{c}^{[l]}$

偏置维度为： 

​                                                           $ 1 \times 1 \times 1 \times n_{c}^{[l]}$

输出维度为 ：

​                                                          $ n_{H}^{[l]} \times n_{W}^{[l]} \times n_{c}^{[l]}$

其中：
$$
\begin{aligned}
n_{H}^{[l]} &=\left\lfloor\frac{n_{H}^{[l-1]}+2 p^{[l]}-f^{[l]}}{s^{[l]}}+1\right\rfloor \\
n_{W}^{[l]} &=\left\lfloor\frac{n_{W}^{[l-1]}+2 p^{[l]}-f^{[l]}}{s^{[l]}}+1\right\rfloor
\end{aligned}
$$
若有$m$个样本进行向量化运算，则输出的维度为：

​                                                                 $m \times n_{H}^{[l]} \times n_{W}^{[l]} \times n_{c}^{[l}$

### 10.8 简单卷积网络示例

![简单卷积网络示例](https://upload-images.jianshu.io/upload_images/16793245-aa200424efe9b118.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

如上图，是一个简单的CNN模型，且$a^{[3]}$维度为7 x 7 x 40，若将$a^{[3]}$排成1列，则维度为1960 x 1，再与输出层连接，输出层若为1个神经元，则为二元分类；若为多个神经元，则为多元分类。由此得出预测输出$\hat{y}$。

当CNN层数增加时，一般$n_{H}^{[l]}$和$n_{W}^{[l]}$会逐渐减小，而$n_{c}^{[l]}$会逐渐增大。

CNN有以下三种类型的layer：

- Convolution（CONV）（最为常见）
- Pooling（POOL）
- Fully connected（FC）

### 10.9 池化层

池化是一种下采样（downsample）手段，是对信息进行抽象的过程。

池化并不只有最大池化Max Pooling一种，不过Max Pooling是最广泛使用的一种。

#### 10.9.1 最大池化 Max Pooling

最大池化指的是在采样区间内用区间内的最大值代表这个区间。

![max Pooling](https://upload-images.jianshu.io/upload_images/16793245-c0bf74e2f4a55db3.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

和卷积运算一样，池化也有自己的参数：池化大小、步长和Padding。只不过最常用的是2*2大小、步长为2和Valid Padding。下文如没有说明则都是采用这种最大池化。

#### 10.9.2 其他池化

* 平均池化：平均池化和最大池化相对应，用该区间的平均值来代表该区间。
* 全局平均池化：和上述池化有点不同，是将一个通道的信息都用该通道的平均值代替。比如输入4\*4\*channels的特征图，输出一个长度为channels的特征向量。该向量每一个值都是对应通道（4*4=16个值）的平均值。通常用在最后一层卷积层后、softmax前。主要作用是代替全连接，降低参数个数。
* ASPP（空洞卷积空间金字塔池化，Atrous Spatial Pyramid Pooling）：和传统的池化操作不同，该池化并不降低分辨率（输出特征图的大小），但是同样可以起到对增加感受野的效果（下文介绍感受野）。

#### 10.9.3 池化的作用

在介绍池化的作用前，先介绍一下感受野。

**感受野 Receptive Field**

感受野表示了一个神经元（输出图的一个像素点）与多少个**原始图像**上的像素点有关联。浅层的感受野小，深层的感受野逐渐增大。对于单个神经元，其值只与其感受野有关，与感受野外无关。下图给出在经过两层3\*3的卷积后的神经元的感受野示例。

![感受野.jpg](https://upload-images.jianshu.io/upload_images/16793245-5ae16ee38d75c2ae.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上图还可以发现，两个3\*3的卷积核能够与单个5\*5的卷积核有相同的感受野。但是前者只有2\*3\*3=18个参数，后者有5\*5=25个参数。可见可以通过多层小的卷积核来获得和单个大卷积核的相同效果，同时参数更少。甚至可以在GoogleNet中看到将n\*n拆分为1\*n和n\*1两个卷积核的做法。

对于池化层有效的原因之一，在于池化操作可以只用少量的参数大大增加下一层的神经元的感受野。方便起见，下列感受野计算不计算到原始图像那层。如果卷积层之间没有加入池化层，那后一层的神经元的感受野只为3\*3=9（假设是3\*3的卷积核）；如果加入了最大池化层，那后一层的神经元的感受野可以增大到3\*3\*4=36，用同样的参数数量直接扩大了4倍。当然，简单地增加卷积核的大小也可以增加感受野，但是这样做增加了计算成本、参数数量、以及过拟合的风险。

**作用**

介绍完感受野，现在开始正式介绍池化的作用：

* 降低分辨率、降维、压缩特征、可以减少后续的运算量等等。但是在某些需要保持分辨率的任务（图像语义分割）中会变成一种弊端。
* 只用少量参数就可以大大增加后续神经元的感受野。

### 10.10 卷积神经网络示例

#### 10.10.1 LeNet5

LeNet的[论文连接](https://ieeexplore.ieee.org/document/726791?reload=true&arnumber=726791)。LeNet是一个很简单很小的网络，建立之初是为了手写字识别（0-9）。虽然简单，但是是第一个典型的CNN网络。麻雀虽小，五脏俱全，包含了卷积层、池化层和全连接层。

网络结构如下：

![图](https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131615671-367457714.png)



该图没有说清楚，网络中所有卷积层的卷积核都是5*5的，以及步长为1，padding为0。图中的subsampling指的是池化，具体来说是最大池化。细心的话还会留意到最后一层用了Gaussian connections。我个人认为已经被淘汰了，感兴趣的可以自行了解。自己实现的时候当成全连接也可以。

该论文的典型之处主要在于：

* 一层卷积一层池化交替出现。
* 最后输出前若干层采用全连接层。
* 全连接层的参数真的很多。卷积网络的参数主要集中在第一层全连接层（16\*5\*5\*120=48000）。

#### 10.10.2 AlexNet

AlexNet的[论文连接](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)。这是第一个引起大家注意的卷积网络，该模型取得了2012年的ImageNet比赛冠军，而且也正是因为这次比赛而打响了名号。

网络结构如下：

![图片](https://imgconvert.csdnimg.cn/aHR0cDovL3BpY3R1cmUucGlnZ3lnYWdhLnRvcC9BbGV4TmV0L0FsZXhOZXQucG5n?x-oss-process=image/format,png)

论文中该图片有误，第一个卷积层的输出应该是54\*54而不是55\*55，这个可以自己计算一下来验证。该网络在前两层就采用了相当大的卷积核，不过后面的层都只用3*3的了。该网络拿下冠军时，以比第二名少20%左右的误差率而取得优胜。

个人认为比较值得注意的点是：

* 并不一定需要每层卷积层后都添加池化层。连续多层卷积层可以视为一层卷积核更大、能拟合更复杂函数的卷积层。
* 对于更大的图片，感受野也需要对应增大。AlexNet的做法是前两层卷积层用了较大的卷积核。

#### 10.10.3 VGG16

VGG16的[论文连接](https://arxiv.org/abs/1409.1556)。该网络改进了AlexNet，改进的思路是：用更多层、更小的卷积核代替原来那些比较大的卷积核。最根本的一点是在不减小感受野的前提下增加层数和减少参数量。从结果上来看，这么做确实起到了不错的效果。

下图中，卷积层默认步长为1，padding为same。网络结构如下：

![我的VGG16.png](https://upload-images.jianshu.io/upload_images/16793245-a89f5559508ad15c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

该网络不止是本身很有价值，其来源（论文）也很有价值。该论文通过对比各种网络，来说明卷积网络越深效果越好这一点。VGG16中的16就是指除去池化层，该网络一个有16层。

对比AlexNet，该网络的改进如下：

* 采用多层连续的3*3卷积层代替大卷积层。
* 网络深度更深了。
* 通道数全部用2的幂。更符合计算机的存储规则。
* 两、三层卷积层 + 一层池化。
* 池化后通道数翻倍。
* 每层网络的步长都为1，padding都为same。

上述改进也是现在我所看到的大部分网络的构建习惯（趋势）。我想这足以说明这些“规律”有多好用。

### 10.11 为什么使用卷积

#### 10.11.1 减少参数

1.10介绍的网络也基本可以看出，卷积网络中全连接层的参数占了绝大一部分。举例LeNet5，各层参数个数分别为：第一层卷积层 5\*5\*1\*6=150、第二层卷积层 5\*5\*6\*16=2400、第一层全连接层 5\*5\*16\*120=48000、第二层全连接层 120\*84=10080，若最后一层视为全连接层则有 84\*10=840。

不难发现，第一层全连接层的参数占据了$\frac{48000}{150+2400+48000+10080+840}=0.78=78%$的参数，这已经占据了一半以上的参数。很明显，卷积层对比全连接层来说可以大大减小参数的数量，一方面可以避免过拟合，另一方面减少了对设备的要求。

更进一步，卷积操作需要的参数很少的原因在于

* **权值共享**。一个卷积核的权值可以适用到整个网络，而不是每个神经元独占一个权值。因为一个卷积核的工作可以理解为专门识别某一些特征。而且这个特征应该是通用的，与所处位置无关，即**平移不变性**。同时平移不变性也是网络学习的潜在目标之一。举例垂直边缘检测便可以检索对应区域是否有垂直边界，而不在乎这个边界的具体位置在哪。
* **稀疏连接**。与全连接对应，在全连接中任意一个神经元都要与上一层的所有神经元连接；而卷积则只受感受野内的神经元影响，对于感受野外的并不关心。

#### 10.11.2 训练卷积网络

假设要做一个猫咪检测网络，$x^{(i)}$表示第$i$张图片，$y^{(i)}$表示对应图片的标签。在选定一个网络后，设计好损失函数，对全部样本的损失求平均作为代价函数。随机初始化权重矩阵和偏置。在Python实现时还可以向量化$x^{(i)}$（当然，就我所知大部分架构也会这么做）。用梯度下降来训练网络，而且也可以采用优化器如$RMSProp$或$Adam$。

