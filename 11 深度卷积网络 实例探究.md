#第二周 深度卷积网络：实例探究
## 2.1为什么要实例探究

  在计算机视觉的研究中，将卷积层、池化层及全连接层进行有有机结合，才能形成有效的卷积神经网络，而更好地去实现这种有机结合可以多多参考他人所构建的框架，而且在计算机视觉中，良好的神经网络框架往往也适用于其他的任务，所以多多参考其他案例有利于我们更好地应用卷积神经网络。在框架学习中，我们也可以多多研读计算机视觉领域相关的论文或相关的研讨内容。



## 2.2经典网络

### 2.2.1LeNet-5网络

![image-20201010103358022](C:\Users\fan\Desktop\repo_深度学习\image-20201010103358022.png)

该网络是针对灰度图像训练的，该例用其对手写字体进行识别

在池化后选用$sigmoid$函数来进行非线性函数处理

其结构为卷积——池化——卷积——池化——全连接——全连接。

且采取了平均池化（当时年代的人们更倾向使用平均池化），然而现在会更多的使用最大池化。因没有使用padding或有效卷积，使得每完成一次卷积，图像的高度和宽度都缩小了。

最后输出层利用了$softmax$函数来分类输出十种结果。

相比于其他更复杂的神经网络，其参数较少，只有约六万个。

随着网络层次的加深，图像的高度和宽度都在缩小，信道数量则会增加。

其中的“一个或多个卷积层后跟着一个池化层，然后又是若干个卷积层，池化层，然后再是全连接层，最后输出。”这一模式仍被经常使用。

### 2.2.2AlexNet网络

![image-20201010105308797](C:\Users\fan\Desktop\repo_深度学习\image-20201010105308797.png)

相比于LeNet-5，AlexNet网络要大得多，其有约六千万个参数，但优点在于在用于训练图像和数据集时，它能处理非常相似的基本构造模块，而往往这些模块有着隐藏单元或数据；同时采用了$Relu$函数。

在写这篇论文时，GPU的处理速度并不快，所以针对这个模型，采用了两个GPU进行训练，将不同的层拆分到两个GPU中进行训练，并用了一些专门的方法使这两个GPU得以交流。

### 2.2.3VGG-16

![image-20201010133618009](C:\Users\fan\Desktop\repo_深度学习\image-20201010133618009.png)

VGG-16中的“16”代表该网络结构包含16个卷积层和全连接层

这是一个极大的网络，约有1.38亿个参数，但其优点是其结构不复杂，一般为卷积层后跟着可压缩图像大小（高度和宽度）的池化层。其过滤器数量变化存在一定规律，变化为64→128→256→512，论文作者可能认为512的信道数量已经足够大了，故没有继续增加。除了VGG-16外，还有VGG-19模型，但VGG-19模型比VGG-16要大得多，但实现的效果并不比VGG-16要好多少，故较少使用VGG-19。

随着该网络的加深，图像的高度和宽度在不断缩小，每次池化后缩小一半，而信道数量在不断增加（每次卷积后增加1倍）。即图像缩小的比例和信道增加的比例是有规律的。



## 2.3残差网络

神经网络层数越多，网络越深，越容易受到梯度消失和梯度爆炸的影响。我们可以通过让神经网络某些层跳过下一层神经元的连接，隔层相连，弱化每层之间的强联系来解决该问题。而这样的神经网络即为残差网络（ResNets）

### 2.3.1残差块

残差网络由多个残差块组成，如下图为残差块组成

![image-20201010140340956](C:\Users\fan\AppData\Roaming\Typora\typora-user-images\image-20201010140340956.png)

图中红色箭头称为跳远连接，其建立了$a^{[l]}$与$a^{[l+2]}$的隔层联系。具体表达式为：

$z^{[l+1]}=W^{[l+1]} a^{[l]}+b^{[l+1]}$ 
$a^{[l+1]}=g\left(z^{[l+1]}\right)$
$z^{[l+2]}=W^{[l+2]} a^{[l+1]}+b^{[l+2]}$
$a^{[l+2]}=g\left(z^{[l+2]}+a^{[l]}\right)$

其中$a^{[l]}$与$z^{[l+2]}$共同作用，通过ReLU函数输出$a^{[l+2]}$

多个残差块构成了如下图所示的残差网络

![image-20201010141849709](C:\Users\fan\Desktop\repo_深度学习\image-20201010141849709.png)

### 2.3.2与Plain Network对比

我们将非残差网络称为Plain Network，将其与ResNet对比可发现，残差网络可以有效解决梯度消失和梯度爆炸的问题，睡着网络层数的增加，Plain Network的training error甚至可能变大，而ResNet的training error则一直呈现下降趋势。如下图![image-20201010142306479](C:\Users\fan\Desktop\repo_深度学习\image-20201010142306479.png)

详细可参考

[Deep Residual Learning for Image Recognition](extension://ibllepbpahcoppkjjllbabhnigcbffpi/https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)




### 2.4 网络中的网络/1*1卷积

#### 2.4.1 定义

​	也被称为***\*Network in Network\****，对输入的个不同的位置都应用一个全连接层，全连接层的作用是便在输入层上实施一个非平凡（***\*non-trivial\****）计算。简单点说就是将输入数据的通道数进行压缩，压缩成所使用的过滤器的数量大小。

 

#### 2.4.2例子一

​	假设这是一个28×28×192的输入层，可以使用池化层压缩它的高度和宽度，这个过程我们很清楚。但如果通道数量很大，该如何把它压缩为28×28×32维度的层呢？你可以用32个大小为1×1的过滤器，严格来讲每个过滤器大小都是1×1×192维，因为过滤器中通道数量必须与输入层中通道的数量保持一致。但是你使用了32个过滤器，输出层为28×28×32，这就是压缩通道数（![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps1.jpg)）的方法。

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps2.jpg)

 

#### 2.4.3例子二

​	过滤器为1×1，输入一张6×6×32的图片，然后对它做卷积，遍历这36个单元格，计算左图中32个数字和过滤器中32个数字的元素积之和，然后应用***\*ReLU\****非线性函数。

​	我们以其中一个单元为例，它是这个输入层上的某个切片，用这36个数字乘以这个输入层上1×1切片，得到一个实数，像这样把它画在输出中。

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps3.jpg)

 

​	这个1×1×32过滤器中的32个数字可以这样理解，一个神经元的输入是32个数字（输入图片中左下角位置32个通道中的数字），即相同高度和宽度上某一切片上的32个数字，这32个数字具有不同通道，乘以32个权重（将过滤器中的32个数理解为权重），然后应用***\*ReLU\****非线性函数，在这里输出相应的结果。

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps4.jpg)

 

​	一般来说，如果过滤器不止一个，而是多个，就好像有多个输入单元，其输入内容为一个切片上所有数字，输出结果是6×6过滤器数量。

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps5.jpg)

 

 

 

​	所以1×1卷积可以从根本上理解为对这32个不同的位置都应用一个全连接层，全连接层的作用是输入32个数字（过滤器数量标记为![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps6.jpg)，在这36个单元上重复此过程）,输出结果是6×6×#filters（过滤器数量），以便在输入层上实施一个非平凡（***\*non-trivial\****）计算。此时，输入的结果的通道层数取决于过滤器的个数。



#### 2.4.4深度可分离卷积

​	**定义**：一个卷积核负责一个通道，一个通道只被一个卷积核卷积

​	**引用博客**：https://blog.csdn.net/makefish/article/details/88716534

​	相较于一般卷积，深度可分离卷积有着不同的计算方法:

​	在卷积计算时，先用三个卷积对三个通道分别做卷积，这样在一次卷积后，输出3个数，然后这输出的三个数，再通过一个1x1x3的卷积核（pointwise核），得到一个数。下面进行分步解释；

​	第一步，对三个通道分别做卷积，输出三个通道的属性：

​	

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps7.jpg)





​	第二步，用卷积核1x1x3对三个通道再次做卷积，这个时候的输出就和正常卷积一样，是8x8x1：

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps8.jpg)



​	如果要提取更多的属性，则需要设计更多的1x1x3卷积核心就可以(图片引用自原网站。感觉应该将8x8x256那个立方体绘制成256个8x8x1，因为他们不是一体的，代表了256个属性)：：

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps9.jpg)

​	**深度可分离卷积的优点缺点**：

​	对于需要提取大量属性或者特征的情景下，深度可分离卷积随着要提取的属性越来越多，就能够节省更多的参数。当然如果提取的特征属性不多，普通的卷积效果优于深度可分离卷积。





### 2.5 Inception网络

#### 2.5.1作用

​	代替人工决定所使用的过滤器的大小，或者确定是否需要创建卷积层或池化层，

#### 2.5.2 论文链接

​	https://arxiv.org/pdf/1409.4842.pdf

#### 2.5.3主要思想

​	不需要人为决定使用哪个过滤器或者是否需要池化，而是由网络自行确定这些参数，你可以给网络添加这些参数的所有可能值，然后把这些输出连接起来，让网络自己学习它需要什么样的参数，采用哪些过滤器组合。

#### 2.5.4原理

​	利用多种维度的过滤器，分别使用不同的方法，产生大量长宽相等，通道可以不同的输出块，并将这些输出块堆积在一起，产生一个组合了各种类型的参数的输出，从而在后续的训练中，让网络自己学习它需要什么样的参数，采用哪些过滤器组合。

 

​	例如，这是你28×28×192维度的输入层，***\*Inception\****网络或***\*Inception\****层的作用就是代替人工来确定卷积层中的过滤器类型，或者确定是否需要创建卷积层或池化层，我们演示一下。

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps10.jpg)

 

​	如果使用1×1卷积，输出结果会是28×28×#（某个值），假设输出为28×28×64，并且这里只有一个层。

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps11.jpg)

 

​	如果使用3×3的过滤器，那么输出是28×28×128。然后我们把第二个值堆积到第一个值上，为了匹配维度，我们应用***\*same\****卷积，输出维度依然是28×28，和输入维度相同，即高度和宽度相同。

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps12.jpg)

 

​	或许你会说，我希望提升网络的表现，用5×5过滤器或许会更好，我们不妨试一下，输出变成28×28×32，我们再次使用***\*same\****卷积，保持维度不变。

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps13.jpg)

 

​	或许你不想要卷积层，那就用池化操作，得到一些不同的输出结果，我们把它也堆积起来，这里的池化输出是28×28×32。为了匹配所有维度，我们需要对最大池化使用***\*padding\****，它是一种特殊的池化形式，因为如果输入的高度和宽度为28×28，则输出的相应维度也是28×28。然后再进行池化，***\*padding\****不变，步幅为1。

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps14.jpg)

 

​	有了这样的***\*Inception\****模块，你就可以输入某个量，因为它累加了所有数字，这里的最终输出为32+32+128+64=256。***\*Inception\****模块的输入为28×28×192，输出为28×28×256。这就是Inception网络的核心内容。



#### 2.5.5计算成本问题

​	由于进行了多种模型的计算，会造成计算成本会非常的大，如何缩小成本是一个非常重要的一环。

​	下面以5×5过滤器为例计算成本

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps15.jpg)

 

​	这是一个28×28×192的输入块，执行一个5×5卷积，它有32个过滤器，输出为28×28×32。我们来计算这个28×28×32输出的计算成本，它有32个过滤器，因为输出有32个通道，每个过滤器大小为5×5×192，输出大小为28×28×32，所以你要计算28×28×32个数字。对于输出中的每个数字来说，你都需要执行5×5×192次乘法运算，所以乘法运算的总次数为每个输出值所需要执行的乘法运算次数（5×5×192）乘以输出值个数（28×28×32），把这些数相乘结果等于1.2亿（120422400）。

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps16.jpg)

 

​	为了缩小成本，我们使用1*1卷积对输入进行通道缩小。对于输入层，使用1×1卷积把输入值从192个通道减少到16个通道。然后对这个较小层运行5×5卷积，得到最终输出。请注意，输入和输出的维度依然相同，输入是28×28×192，输出是28×28×32。

​	然后我们进行成本计算应用1×1卷积，过滤器个数为16，每个过滤器大小为1×1×192，这两个维度相匹配（输入通道数与过滤器通道数），28×28×16这个层的计算成本是，输出28×28×192中每个元素都做192次乘法，用1×1×192来表示，相乘结果约等于240万，这是第一个卷积层的计算成本。第二层的输出为28×28×32，对每个输出值应用一个5×5×16维度的过滤器，计算结果为1000万。

​	所以所需要乘法运算的总次数是这两层的计算成本之和，也就是1204万，与上一张幻灯片中的值做比较，计算成本从1.2亿下降到了原来的十分之一，即1204万。

 

#### 2.5.6 瓶颈层

 

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps17.jpg)

 

​	这个被增加的1*1卷积层常被称为瓶颈层，即先缩小网络表示，然后再扩大它。

 

​	需要注意的是，只要合理构建瓶颈层，你既可以显著缩小表示层规模，又不会降低网络性能，从而节省了计算。

​	

#### 2.5.7 Inception Net

简述：由多个***\*Inception\*******\*模块所组成的神经网络。\****

原理：

​	首先如下图所示，建立前面所说的***\*Inception\****模块。

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps18.jpg)

 

​	为了能在最后将这些输出都连接起来，我们会使用***\*same\****类型的***\*padding\****来池化，使得输出的高和宽依然是28×28，这样才能将它与其他输出连接起来。

​	但注意，如果你进行了最大池化，即便用了***\*same padding\****，3×3的过滤器，***\*stride\****为1，其输出将会是28×28×192，其通道数或者说深度与这里的输入（通道数）相同。所以看起来它会有很多通道，我们实际要做的就是再加上一个1×1的卷积层，去进行我们在1×1卷积层的视频里所介绍的操作，将通道的数量缩小，缩小到28×28×32。

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps19.jpg)

 

​	最后，将这些方块全都连接起来。在这过程中，把得到的各个层的通道都加起来，最后得到一个28×28×256的输出。通道连接实际就是之前视频中看到过的，把所有方块连接在一起的操作。这就是一个***\*Inception\****模块，而***\*Inception\****网络所做的就是将这些模块都组合到一起。

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps20.jpg)

 

***\*上图为\*******\*Inception\****网络的图片，并且其由多个***\*Inception\*******\*模块所组成，需要注意的是有一些\*******\*Inception\*******\*模块中间还夹着一个最大池化层，如图中的6和7.\****

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps21.jpg)

 

***\*在论文原文中，网络里有着一些其他分支，如上图中的1、2、4，其中1是一个\*******\*softmax\****层，用于做出预测，编号2所做的就是通过隐藏层（编号3）来做出预测，所以这其实是一个***\*softmax\****输出（编号2），编号4也包含了一个隐藏层，通过一些全连接层，然后有一个***\*softmax\****来预测，输出结果的标签。	这些分支确保了即便是隐藏单元和中间层（编号5）也参与了特征计算，它们也能预测图片的分类。它在***\*Inception\****网络中，起到一种调整的效果，并且能防止网络发生过拟合。

 

#### 2.5.8 Inception网络多种类型

​	参考博客：https://www.cnblogs.com/dengshunge/p/10808191.html

##### Inception v1

​	v1其实就是我们前面所说的使用1*1卷积降低计算量后的Inception网络。

​	提升神经网络的性能是各种方法和算法的目的，当然提升网络的性能的方法有很多，例如增加网络的深度和宽度，但当深度和宽度不断增加时，需要训练的参数也会增加，过多的参数容易发生过拟合，并且会导致计算量增加。所以就有了v1结构来解决此问题，也就是利用1*1卷积降低计算量。

 

##### Inception v2

​	在训练时每层输入数据的分布会发生改变，所以需要较低的学习率和精心设置初始化参数。只要网络的前面几层发生微小的改变，那么后面几层就会被累积放大下去。一旦网络某一层的输入数据的分布发生改变，那么这一层网络就需要去适应学习这个新的数据分布，所以如果训练过程中，训练数据的分布一直在发生变化，那么将会影响网络的训练速度。为此，提出了v2版本的Inception网络。

​	V2版本网络使用了BN算法，可以设置较大的初始学习率，并且减少对参数初始化的依赖，提高了训练速度，同时也可以能防止网络陷入饱和，即消除梯度弥散。

 

##### Inception v3

​	Inception v3主要解决的是：inception结构过于复杂，使得我们很难对网络进行修改。

​	V3主要思路为：利用小尺度的卷积来代替大尺度的卷积，在减少计算量的同时，保证能够学习到更多的信息。例如提出了使用两个级联的3*3的滤波器来代替一个5*5的滤波器，如下图所示：

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps22.jpg)

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps23.jpg)

 

​	同时又对3*3卷积进行分解为3*1+1*3，如下图所示，进而进一步降低计算量

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps24.jpg)

 

V3主要遵循下列几条思想

1. 避免特征表示瓶颈，尤其是在网络的前面。要避免严重压缩导致的瓶颈。特征表示尺寸应该温和地减少，从输入端到输出端。特征表示的维度只是一个粗浅的信息量表示，它丢掉了一些重要的因素如相关性结构。

2. 高维信息更适合在网络的局部处理。在卷积网络中逐步增加非线性激活响应可以解耦合更多的特征，那么网络就会训练的更快。

3. 空间聚合可以通过低维嵌入，不会导致网络表示能力的降低。例如在进行大尺寸的卷积（如3*3）之前，我们可以在空间聚合前先对输入信息进行降维处理，如果这些信号是容易压缩的，那么降维甚至可以加快学习速度。

4. 平衡好网络的深度和宽度。通过平衡网络每层滤波器的个数和网络的层数可以是网络达到最佳性能。增加网络的宽度和深度都会提升网络的性能，但是两者并行增加获得的性能提升是最大的。所以计算资源应该被合理的分配到网络的宽度和深度。 

 

##### Inception v4

​	V4的提出主要是基于 ”当网络更深更宽时，inception网络能否一样高效”的问题提出的，v4具体的解决方法为，结合TensorFlow，简化训练，不需要将模型进行分割，并且将inception和resnet两者进行融合，进一步改善网络。



​	以上对Inception网络的4种模型进行概述，具体解释可参考下列博客  https://www.cnblogs.com/dengshunge/p/10808191.html



### 2.6使用开源实现方案

本节为介绍如何下载开源代码。

本节下载的代码网站为：

***\*ResNets\****实现的***\*GitHub\****地址：https://github.com/KaimingHe/deep-residual-networks

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps25.jpg)

 

 

***\*点击Code按钮，并且点击复制按钮复制代码的URL\****

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps26.jpg)

 

在需要保存代码的目录下打开cmd，使用下列指令进行代码的下载（复制）

git clone your URL

git clone https://github.com/KaimingHe/deep-residual-networks.git

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps27.jpg)

 

使用指令观察目录，说明此时代码已下载完毕。

接下来进行打开代码。

 

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps28.jpg)

 

代码储存在prototxt文件夹中

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps29.jpg)

 

使用指令打开其中一个文件。

more 文件名

![img](file:///C:\Users\Samzi\AppData\Local\Temp\ksohtml9832\wps30.jpg)

当然也可以用ide直接打开来进行修改。
### 2.7 迁移学习
#### 2.7.1 迁移学习的概念
迁移学习是从一个或多个源领域中通过训练该模型，得出有用的知识并将其用在新的目标任务上（未标记的同一类有相似特征的物品或者是未标记的不同类物品）本质是知识的迁移再利用。
#### 2.7.2 ImageNet、MS COCO\Pascal数据集的获取
ImageNet数据集的获取：
  所有图像可通过url下载：不需要账号登录即可免费下载，下载链接：http://www.image-net.org/download-imageurls ，在SEARCH框中输入需要下载的synset，如tree，也可按类别下载即WordNet ID，下载链接：http://www.image-net.org/synset?wnid=n02084071 ，其中好像个别url已失效。
MS COCO:

数据集官网首页：http://cocodataset.org/#home

数据集下载：

    可用迅雷去下载官方链接，速度也挺快的。也可以去这个高中生搭建的下载站下载：http://bendfunction.f3322.net:666/share/。 他的首页是这样子的：http://bendfunction.f3322.net:666/
    https://pjreddie.com/projects/coco-mirror/
#### 2.7.3 迁移学习的分类
按照迁移学习的定义，可以将迁移学习分为三种类型，分布差异迁移学习，特征差异迁移学习和标签差异迁移学习。分布差异迁移学习之源域和目标域数据的边缘分布或者条件概率分布不同，特征差异迁移学习之源域数据和目标数据特征空间不同，标签差异迁移学习指源域和目标域的数据标记空间不同。
用香蕉和苹果分类问题为例，源域数据是已有的带标签香蕉和苹果的文本数据，目标域是新来的不带标记的香蕉和苹果的文本数据，源域和目标域的数据来自不同的时间，不同地点，数据分布不同，但标记空间和特征空间是相同的，利用源域中的数据来进行目标域的学习问题就是属于分布差异迁移学习问题。源域数据是带有标记的苹果和香蕉的文本数据，而目标域是不带有 标记的苹果和香蕉的图片数据，源域和目标域一个是文本，一个是图像，属于特征差异迁移学习范围。源域数据是带有标记的香蕉和苹果的文本数据，属于二分类问题，目标域是不带标记的梨子，橘子和橙子的文本数据属于三分类问题，源域和目标域的数据标记空间不同，属于标记差异迁移学习的范围。

现已成熟的监督学习模式下，在大样本的已标记的数据量集中训练形成传统的监督学习，但是这种模式在运用到情况更为复杂，更多变的实际环境中往往会出现很大的误差，
所以迁移学习就是在样本量比较少的情况下，训练分类器，随之把这种模式可以运用到其他很多种情况下。

### 2.8 数据增强
#### 2.8.1数据增强的基本操作
数据增强也叫数据扩增，意思是在不实质性的增加数据的情况下，让有限的数据产生等价于更多数据的价值。
数据增强的手段包括几何变换类，颜色变换类等。

(1) 几何变换类

几何变换类即对图像进行几何变换，包括翻转，旋转，裁剪，变形，缩放等各类操作，下面展示以上操作。
图一2 3  4 5
(2) 颜色变换类
颜色变换类时改变图片的R、G、B的值。
#### 2.8.2数据增强的代码实现
TensorFlow实现图片数据增强：
参见以下网址https://zhuanlan.zhihu.com/p/57284174
#### 2.8.2数据增强的优缺点
优点：
增加训练的数据量，提高模型的泛化能力
增加噪声数据，提升模型的鲁棒性
### 2.9 计算机视觉现状
#### 2.9.1计算机视觉现状
深度学习已经成功地应用于计算机视觉、自然语言处理、语音识别、在线广告、物流还有其他许多问题。
在计算机视觉的现状下，深度学习应用于计算机视觉应用有一些独特之处。
####2.9.2 banchmark
Benchmark 基准测试，Benchmark是一个评价方式，在整个计算机领域有着长期的应用。
Benchmark在计算机领域应用最成功的就是性能测试，主要测试负载的执行时间、传输速度、吞吐量、资源占用率等。基准测试同时也可以用来识别某段代码的CPU或者内存效率问题. 许多开发人员会用基准测试来测试不同的并发模式, 或者用基准测试来辅助配置工作池的数量, 以保证能最大化系统的吞吐量.
关于实战可参考： 
https://blog.csdn.net/woniu317/article/details/82560312
