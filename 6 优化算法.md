## 6 优化算法

### 6.1 基于梯度的优化方法

#### 6.1.1 简介

**优化指的是改变 $x$ 以最小化或最大化某个函数 $f(x)$ 的任务**。我们通常以最小化 $f(x)$ 指代大多数最优化问题。最大化可经由最小化算法最小化 $-f(x)$ 来实现。假设我们有一个函数 $y=f(x)$,其中 $x$ 和 $y$ 是实数 这个函数的导数记为 $f^{\prime}(x)$ 或 $\frac{d y}{d x} $。导数 $f^{\prime}(x)$ 代表 $f(x)$ 在点 $x$ 处的斜率。换句话说，它表明如何缩放输入的小变化才能在输出获得相应的变化: $f(x+\epsilon) \approx f(x)+\epsilon f^{\prime}(x)$。因此导数对于最小化一个函数很有用，因为它告诉我们如何更改 $x$ 来略微地改善 $y$ 。例如，我们知道对于足够小的 $\epsilon$ 来说， $f\left(x-\epsilon \operatorname{sign}\left(f^{\prime}(x)\right)\right)$ 是比 $f(x)$ 小的。因 此我们可以将 $x$ 往导数的反方向移动一小步来减小 $f(x)$ ，这种技术被称为梯度下降 （gradient descent )。
当 $f^{\prime}(x)=0$, 导数无法提供往哪个方向移动的信息。 $f^{\prime}(x)=0$ 的点称为**临界点 ( critical point) 或 驻点（stationary point )**。一个局部极小点 ( local minimum) 意味着这个点的 $f(x)$ 小于所有邻近点，因此不可能通过移动无穷小的步长来减小 $f(x)$ 。一个局部极大点 ( local maximum ) 意味着这个点的 $f(x)$ 大于所有邻近点，因此不可能通过移动无穷小的步长来增大 $f(x)$ 。有些临界点既不是最小点也不是最大点，这些点被称为鞍点（Saddle point），如下图所示：

![image-20210419225516388](https://i.loli.net/2021/04/19/85SDdYfZqKAvpyQ.png)

在深度学习中，我们很难找到全局极小点，大概率会找到局部极小点，但只要他们对应于代价函数显著低的值，我们通常就能接受这样的解。

#### 6.1.2 梯度下降法

我们经常最小化具有多维输入的函数: $f: \mathbb{R}^{n} \rightarrow \mathbb{R}_{\circ}$ 为了使 “最小化" 的概念有意义，输出必须是一维的 (标量)。
针对具有多维输入的函数，我们需要用到偏导数（partial derivative ) 的概念。 **偏导数 $\frac{\partial}{\partial x_{i}} f(\boldsymbol{x})$ 衡量点 $x$ 处只有 $x_{i}$ 增加时 $f(x)$ 如何变化**。 **梯度（gradient ) 是相对一个向量求导的导数: $f$ 的导数是包含所有偏导数的向量，记为 $\nabla_{x} f(\boldsymbol{x})$ 。梯度的第 $i$ 个元素是 $f$ 关于 $x_{i}$ 的偏导数**。在多维情况下，临界点是梯度中所有元素都为零的 点。
在 $u$ (单位向量 ) 方向的方向导数（ directional derivative ) 是函数 $f$ 在 $u$ 方向 的斜率。换句话说，方向导数是函数 $f(x+\alpha \boldsymbol{u})$ 关于 $\alpha$ 的导数（在 $\alpha=0$ 时取得 )。 使用链式法则 ，我们可以看到当 $\alpha=0$ 时 , $\frac{\partial}{\partial \alpha} f(\boldsymbol{x}+\alpha \boldsymbol{u})=\boldsymbol{u}^{\top} \nabla_{x} f(\boldsymbol{x})$ 。

为了最小化 $f$ ，我们希望找到使 $f$ 下降得最快的方向。计算方向导数:
$$
\begin{aligned}
\min _{u, u^{\top} u=1} \boldsymbol{u}^{\top} \nabla_{x} f(\boldsymbol{x}) \\
=\min _{u, u^{\top} u=1}\|\boldsymbol{u}\|_{2}\left\|\nabla_{x} f(\boldsymbol{x})\right\|_{2} \cos \theta
\end{aligned}
$$
其中 $\theta$ 是 $u$ 与梯度的夹角。将 $\|u\|_{2}=1$ 代入，并忽略与 $u$ 无关的项，就能简化得 到 $\min \cos \theta_{\circ}$ 这在 $u$ 与梯度方向相反时取得最小。换句话说，梯度向量指向上坡, 负梯度向量指向下坡。我们在负梯度方向上移动可以减小 $f_{\circ}$ 这被称为最速下降法 (method of steepest descent) 或 梯度下降（gradient descent )。
梯度下降建议新的点为
$$
x^{\prime}=x-\epsilon \nabla_{x} f(x)
$$
其中 $\epsilon$ 为学习率（learning rate )，是一个确定步长大小的正标量。我们可以通过儿 种不同的方式选择 $\epsilon_{\circ}$ 普遍的方式是选择一个小常数。有时我们通过计算，选择使方向导数消失的步长。还有一种方法是根据几个 $\epsilon$ 计算 $f\left(x-\epsilon \nabla_{x} f(x)\right)$, 并选择其中 能产生最小目标函数值的 $\epsilon$，**这种策略被称为线搜索**。

梯度下降在梯度的每一个元素为0时收敛（或在实践中，很接近0时 )。在某些情况下，我们也许能够避免运行该迭代算法，并通过解方程 $\nabla_{x} f(\boldsymbol{x})=0$ 直接跳到下 界点。**虽然梯度下降被限制在连续空间中的优化问题**，但不断向更好的情况移动一小 战 (即近似最佳的小移动 ) 的一般概念可以推广到离散空间。递增带有离散参数的目标函数被称为 爬山（ hill climbing ) 算法：爬山算法是一种局部择优的方法，采用启发式方法，是对深度优先搜索的一种改进，它利用反馈信息帮助生成解的决策。直白地讲，就是当目前无法直接到达最优解，但是可以判断两个解哪个更优的时候，根据一些反馈信息生成一个新的可能解。因此，爬山算法每次在当前找到的最优方案 x附近寻找一个新方案。如果这个新的解 x‘更优，那么转移到 x’，否则不变。

#### 6.1.3 Jacobian（雅克比）和Hessian（黑塞）矩阵

设 $f: \mathbb{R}_{n} \rightarrow \mathbb{R}_{m}$ 是一个函数, 它的输入是向量 $\mathbf{x} \in \mathbb{R}_{n}$, 輸出是向量 $\mathbf{y}=f(\mathbf{x}) \in \mathbb{R}_{m}:$
                                                                                                       $\left\{\begin{array}{l}y_{1}=f_{1}\left(x_{1}, \ldots, x_{n}\right) \\ y_{2}=f_{2}\left(x_{1}, \ldots, x_{n}\right) \\ \cdots \\ y_{m}=f_{m}\left(x_{1}, \ldots, x_{n}\right)\end{array}\right.$
那么雅可比矩阵是一个 $\mathrm{m} \times \mathrm{n}$ 矩阵:
                                                             $\mathbf{J}=\left[\begin{array}{lll}\frac{\partial \mathbf{f}}{\partial x_{1}} & \cdots & \frac{\partial \mathbf{f}}{\partial x_{n}}\end{array}\right]=\left[\begin{array}{ccc}\frac{\partial f_{1}}{\partial x_{1}} & \cdots & \frac{\partial f_{1}}{\partial x_{n}} \\ \vdots & \ddots & \vdots \\ \frac{\partial f_{m}}{\partial x_{1}} & \cdots & \frac{\partial f_{m}}{\partial x_{n}}\end{array}\right]$
由于矩阵描述了向量空间中的运动一一变换, 而雅可比矩阵看作是将点 $\left(x_{1}, \ldots, x_{n}\right)$ 转化到点 $\left(y_{1}, \ldots, y_{m}\right)$, 或者说是从一个维的欧式空间转换到m维的欧氏空间。

如果m $=\mathrm{n}, \quad$ 可以定义雅可比矩阵 $\mathbf{J}$ 的行列式, 也就是雅可比行列式 (Jacobian determinant)。

有时，我们也对导数的导数感兴趣，即 二阶导数（ second derivative )。例如，有 个函数 $f: \mathbb{R}^{m} \rightarrow \mathbb{R}, f$ 的一阶导数 $\left(\right.$ 关于 $\left.x_{j}\right)$ 关于 $x_{i}$ 的导数记为 $\frac{\partial^{2}}{\partial x_{i} \partial x_{j}} f_{\circ}$ 在一维情况下，我们可以将 $\frac{\partial^{2}}{\partial x^{2}} f$ 为 $f^{\prime \prime}(x)_{\circ}$ 二阶导数告诉我们，一阶导数将如何随着输人 的变化而改变。它表示只基于梯度信息的梯度下降步骤是否会产生如我们预期的那样大的改善，因此它是重要的。我们可以认为，二阶导数是对曲率的衡量。假设我 们有一个二次函数（虽然很多实践中的函数都不是二次的，但至少在局部可以很好地用二次近似 $)$ 。如果这样的函数具有零二阶导数，那就没有曲率。也就是一条完全平坦的线，仅用梯度就可以预测它的值。我们使用沿负梯度方向大小为 $\epsilon$ 的下降步， 当该梯度是 1 时，代价函数将下降 $\epsilon_{\circ}$ 如果二阶导数是负的，函数曲线向下口陷 (向上凸出)，因此代价函数将下降的比 $\epsilon$ 多。如果二阶导数是正的，函数曲线是向上凹 陷(向下凸出)，因此代价函数将下降的比 $\epsilon$ 少。如下图所示：

![image-20210420170045096](https://i.loli.net/2021/04/20/Mv2JNc9foPwQC5F.png)

当我们的函数具有多维输入时，二阶导数也有很多。我们可以将这些导数合并成一个矩阵，称为 Hessian（ Hessian）矩阵。Hessian 矩阵 $\boldsymbol{H}(f)(\boldsymbol{x})$ 定义成
$$
\boldsymbol{H}(f)(\boldsymbol{x})_{i, j}=\frac{\partial^{2}}{\partial x_{i} \partial x_{j}} f(\boldsymbol{x})
$$
Hessian 等价于梯度的 Jacobian 矩阵。
**微分算子在任何二阶偏导连续的点处可交换**，也就是它们的顺序可以互换：
$$
\frac{\partial^{2}}{\partial x_{i} \partial x_{j}} f(\boldsymbol{x})=\frac{\partial^{2}}{\partial x_{j} \partial x_{i}} 
f(\boldsymbol{x})
$$
这意味着 $H_{i, j}=H_{j, i}$, 因此 Hessian 矩阵在这些点上是对称的。在深度学习背景下, 我们遇到的大多数函数的 Hessian 几乎处处都是对称的。**因为 Hessian 矩阵是实对称的，我们可以将其分解成一组实特征值和一组特征向量的正交基**。在特定方向 $d$ 上的二阶导数可以写成 $d^{\top}$ Hd 。当 $d$ 是 $H$ 的一个特征向量时，这个方向的二阶导数就是对应的特征值。对于其他的方向 $d$, 方向二阶导数是所有特征值的加权平均，**权重在 0 和 1 之间，且与 $d$ 夹角越小的特征向量的权重越大。最大特征值确定最大二阶导数，最小特征值确定最小二阶导数**。我们可以通过 $($ 方向 $)$ 二阶导数预期一个梯度下降步骤能表现得多好。我们在当前点 $x^{(0)}$ 处作函数 $f(x)$ 的近似二阶泰勒级数:
$$
f(\boldsymbol{x}) \approx f\left(\boldsymbol{x}^{(0)}\right)+\left(\boldsymbol{x}-\boldsymbol{x}^{(0)}\right)^{\top} \boldsymbol{g}+\frac{1}{2}\left(\boldsymbol{x}-\boldsymbol{x}^{(0)}\right)^{\top} \boldsymbol{H}\left(\boldsymbol{x}-\boldsymbol{x}^{(0)}\right)
$$
其中 $g$ 是梯度， $H$ 是 $x^{(0)}$ 点的 $\operatorname{Hessian}_{\circ}$ 如果我们使用学习率 $\epsilon$, 那么新的点 $x$ 将 会是 $x^{(0)}-\epsilon \boldsymbol{g}_{\circ}$ 代入上述的近似，可得
$$
f\left(\boldsymbol{x}^{(0)}-\epsilon \boldsymbol{g}\right) \approx f\left(\boldsymbol{x}^{(0)}\right)-\epsilon \boldsymbol{g}^{\top} \boldsymbol{g}+\frac{1}{2} \epsilon^{2} \boldsymbol{g}^{\top} \boldsymbol{H} \boldsymbol{g}
$$
其中有 3 项：**函数的原始值、函数斜率导致的预期改善、函数曲率导致的校正**。当最后一项太大时，梯度下降实际上是可能向上移动的。当 $g^{\top} H g$ 为零或负时，近似的泰勒级数表明增加 $\epsilon$ 将永远使 $f$ 下降。在实践中，泰勒级数不会在 $\epsilon$ 大的时候也保持准确，因此在这种情况下我们必须采取更启发式的选择。当 $g^{\top} H g$ 为正时，通 过计算可得，使近似泰勒级数下降最多的最优步长为：
$$
\epsilon^{*}=\frac{\boldsymbol{g}^{\top} \boldsymbol{g}}{\boldsymbol{g}^{\top} \boldsymbol{H} \boldsymbol{g}}
$$
最坏的情况下， $g$ 与 $H$ 最大特征值 $\lambda_{\max }$ 对应的特征向量对齐，则最优步长是 $\frac{1}{\lambda_{\text {max }}}$ 我们要最小化的函数能用二次函数很好地近似的情况下，**Hessian 的特征值决定了学习率的量级。**
二阶导数还可以被用于确定一个临界点是否是局部极大点、局部极小点或鞍点。回想一下，在临界点处 $f^{\prime}(x)=0_{\circ}$ 而 $f^{\prime \prime}(x)>0$ 意味着 $f^{\prime}(x)$ 会随着我们移向右边而增加，移向左边而减小，也就是 $f^{\prime}(x-\epsilon)<0$ 和 $f^{\prime}(x+\epsilon)>0$ 对足够小的 $\epsilon$ 成立。换句话说，当我们移向右边，斜率开始指向右边的上坡，当我们移向左边，斜率开始指向左边的上坡。因此我们得出结论，**当 $f^{\prime}(x)=0$ 且 $f^{\prime \prime}(x)>0$ 时,$x$ 是一个局部极小点。同样，当 $f^{\prime}(x)=0$ 且 $f^{\prime \prime}(x)<0$ 时,$x$ 是一个局部极大点**。这就是所谓的二阶导数测试 ( second derivative test)。不幸的是，当 $f^{\prime \prime}(x)=0$ 时测试是不确定的。在这种情况下， $x$ 可以是一个鞍点或平坦区域的一部分。















### 6.1 Mini-batch 梯度下降 

传统的梯度下降，每次梯度下降都是对所有的训练数据进行计算平均梯度，这种梯度下降法叫做full-batch梯度下降法。考虑一种情况，当训练数据量在千万级别时，一次迭代需要等待多长时间，会极大的降低训练速度。每次训练的使用同一份数据，所以loss的损失函数会是一直下降的，收敛到的是全局最优解。如果选择介于1和最大训练数据量之间的一个bath size数据量进行训练，叫mini-batch 梯度下降。

### 6.2 理解mini-batch梯度下降法

![图1.png](https://upload-images.jianshu.io/upload_images/24435917-aa8bcaf7b24d7922.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

当batch size 为1时，如图一中红色变化示意图，每一个训练数据都要更新权值。通过小的学习率，噪声也会小很多，但舍弃了向量化处理带来的加速，这种梯度下降叫随机梯度下降（SGD）；

当batch_size为mini batch时，如图中蓝色变化示意图，每一个batch更新一次去权值。下降会有一些噪声变化，但是总体趋势是走向拟合中心的；

当batch_size为full batch时，如图中黑色变化示意图，全部数据训练完更新一次权值。下降时变化很快，一直是趋于拟合的，但是当数据量大时，单次迭代时间过长，这种梯度下降叫BGD(batch gradient descent)。

### 6.3指数加权平均数

平均数求法:
比如我们现在有100天的温度值，要求这100天的平均温度值。
24，25，24，26，34，28，33，33，34，35..........32。
我们直接可以用公式：
$$
v_{\text {aver }}=\frac{v_{1}+\ldots+v_{100}}{100}
$$
通过该的公式就可以直接求出100天的平均值。而我们要介绍的指数加权平均本质上就是一种近似求平均的方法。
指数加权平均：

![图3.png](https://upload-images.jianshu.io/upload_images/24435917-ee6a1a5a5f8e1461.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

​                                                                                                                  $$v_t=\beta v_{t-1}+(1-\beta )\theta_t \\
\vdots \\
v_{100}=0.9 v_{99}+0.1 \theta_{100}\\
v_{99}=0.9 v_{98}+0.1 \theta_{99}\\
v_{98}=0.9 v_{97}+0.1 \theta_{98}\\$$

化简开得到：

![图5.png](https://upload-images.jianshu.io/upload_images/24435917-dc8658bf1b36cc1c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

通过上面表达式，可以看出，V100等于每一个时刻天数的温度值再乘以一个权值。
本质就是以指数式递减加权的移动平均。各数值的加权而随时间而指数式递减，越近期的数据加权越重，但较旧的数据也给予一定的加权。
**指数加权平均的结果是由当天温度值乘以指数衰减函数值，然后类和即可求得**。

### 6.4 指数加权平均数的实现

指数加权平均法的实现：
$$
\begin{array}{l}
v_{0}=0 \\
v_{1}=\beta v_{0}+(1-\beta) \theta_{1} \\
v_{2}=\beta v_{1}+(1-\beta) \theta_{2} \\
v_{3}=\beta v_{2}+(1-\beta) \theta_{3}
\end{array}
$$
我们可以看到指数加权平均的求解过程实际上是一个**递推**的过程，那么这样就会有一个非常大的好处，每当我要求从0到某一时刻（n）的平均值的时候，我并不需要像普通求解平均值的作为，保留所有的时刻值，类和然后除以n。而是只需要保留0-(n-1)时刻的平均值和n时刻的温度值即可。也就是每次只需要保留常数值，然后进行运算即可，**这对于深度学习中的海量数据来说，是一个很好的减少内存和空间的做法**。

### 6.5 指数加权平均的偏差修正

指数加权平均的偏差修正是为了让平均数的计算更加准确。具体实现方法如下图所示：

![图7.png](https://upload-images.jianshu.io/upload_images/24435917-f1d630759c12b415.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上一节的例子中，我们介绍了当$\beta$取0.98时，我们的拟合曲线应该是绿色那条，但这样说是不太准确的，因为在我们将V0初始化为0的条件下，我们拟合的曲线应该是紫色那条，而这两条曲线区别就在前面一小部分。为什么会有这样结果呢？我们可以用实例计算一下，如上图所示， 令V0=0，且 $\beta$=0.98，我们可以得到V1、V2结果如上图所示，假设前两天的温度都为40度，那么通过V2的计算式我们可以推出V2约为8度，比绿线值低很多。

我们可以使用上图中右侧式子进行修正，即$$
\frac{V_{t}}{1-\beta^{t}}
$$，比如当t等于2时，V2就可以通过该式子进行修正。发现这个修正只对前部分数据作用较大，因为随着t的增加，
$$
1-\beta^{t}
$$
的值也会趋近于1。其实通过偏差修正，我们可以更加理解用指数加权移动平均来代替平均数计算的原因，因为修正后的温度值实际上是之前温度值的加权平均，比如在该例中，0.0196+0.02=0.0396。其实我们用数学方法也可以很容易证明，在该例中，就是 

$$
\beta(1-\beta)+(1-\beta)=1-\beta^{2}
$$
 所以当t很大时，对Vt而言，前t时刻所有实际温度的权重和近似为1。

但其实在实际中，有些人在训练中并不care前部分曲线的拟合情况，而是直接使用未修正的，这样也可以，但是我们要明白偏差修正的意义，那就是为了让平均数计算得更准确。

### 6.6 $Momentum$梯度下降

#### 6.6.1 原理

$Momentum$梯度下降法又叫动量梯度下降法。该梯度下降的思路和一个球往碗底（或者其他低地）滚的过程有点像：

初动量$v$为0，然后在“重力”的影响下获得加速度$d\theta$，动量发生变化，于是“位置”$\theta$也跟着发生改变；位置改变由引起加速度的变化，周而复始，最终“位置”处于最平稳的地带，此时加速度和动量基本为0。

更具体来说，就是每次参数的更新从

$$\theta = \theta - \alpha d\theta$$

变为

$$\theta = \theta - \alpha v$$

其中，$v$初始值为0，更新公式为：

$$v = \beta_1 v+(1-\beta_1)d\theta$$

该公式应用了指数加权平均，**将$v$视为$d\theta$的指数加权平均**。上述公式中，$\alpha$为学习率，$\beta_1$为衰减率（decay rate）。至于加上下标$1$主要是为了与下文的$\beta$进行区分。

#### 6.6.2 优势

该算法有两点很巧妙，也是其优势：

* $\beta_1$的作用可以理解为添加了一个“摩擦力”：由于$\beta_1 \in [0,1)$，所以每次更新都会让原来的动量减小（在加速度较小的前提下）；让动量减小的目的在于**最终能在底部停下来**，收敛到最优解。
* 由于更新的时候并没有完全舍弃前一次的动量，所以会有一个动量叠加的过程：如果接下来的加速度方向大体一致，则动量会累计起来然后以一个**较快的速度**滚动，加快学习速度。
* 由于动量的叠加，还拥有了“**惯性**”这个特性：在有一定动量之后，可以跨越障碍（如图示效果可以跨过第一个坑）。

#### 6.6.3 图示效果

![img](https://pic4.zhimg.com/v2-35bdfd6c71d45865ea822b2bd9670b19_b.webp)

紫色球为$Momentum$梯度下降，蓝色球为普通2梯度下降。可见由于之前积累下来了动量（又或者说惯性），所以紫球可以“冲出”局部最优解然后到达全局最优解。图源自[这里](https://zhuanlan.zhihu.com/p/147275344?utm_source=wechat_session)。

#### 6.6.4 实现

代码实现：

```python
# 需要参数：学习率alpha和衰减率（动量参数）beta_1，beta_1通常取0.9
# 在梯度下降的循环里面
# 已经计算了梯度dW和db
# v_dW和v_db初始化为0，shape分别和dW，db一致
v_dW = beta_1 * v_dW + (1-beta_1) * dW
v_db = beta_1 * v_db + (1-beta_1) * db

W = W - alpha * v_dW
b = b - alpha * v_db
```

有时候也可以采用公式

$$v = \beta_1 v + d\theta$$

来更新动量，不过此时的最佳$\alpha$也会发生相应的变化。采用这条公式相当于原来的动量乘以$\frac {1}{1-\beta}$。学习速度应该会更快，但也更不稳定（动量太大停下来需要更多的时间）。

#### 6.6.5 其他

如果有读过相关论文或者花书，会发现大多数的实现的具体方式与上述有所区别。大部分采用的是下式：

> 动量$v$的更新公式：$v=\beta v - \alpha d\theta$
>
> 参数的更新公式：$\theta=\theta + v$

其实两者没有本质的区别，基本原理还是一样的。大部分论文中采用的公式是该算法被提出时的原型，也更接近真正的球滚来滚去的模型；吴恩达老师教的则是另一种实现方式（同时也是大部分封装库采用的方式）。

并没找到相关解释，个人猜测这么做的原因是为了与$RMSprop$的形式更相似。并且可能是在$Adam$的论文中第一次出现这种实现——也是$Momentum$第一次和$RMSprop$“合作”（大概，没有具体核实）。

### 6.7 $RMSprop$

#### 6.7.1 原理

$RMSprop$全称$root$ $mean$ $square$ $prop$。会出现这个算法的主要原因是想解决一个问题：普通的梯度下降对于**稀疏特征**（大意是指0很多的特征）的学习效果很差。因为稀疏特征的0很多，导致平均梯度会很小，进而导致网络对于稀疏特征的学习很慢（对比于更密集的特征）。

为了让稀疏特征的学习速度和密集特征的学习速度不会差距太大，$RMSprop$的解决思路如下：

$$\begin{array}{l}
s = \beta_2 s + (1-\beta_2)(d\theta)^2 \\ 
\theta = \theta - \alpha \frac{d\theta}{\sqrt s}
\end{array}$$

其中梯度平方的指数加权平均$s$的初始值为0，$\alpha$为学习率，$\beta_2$为衰减率。不难见得，参数更新时，是通过除以$\sqrt s$的方式来让各个特征的梯度都趋于"$1$"（并不一定真的是$1$），以保证每个特征的学习速度是基本一致的。毕竟之前的梯度越大，$\sqrt s$就越大，$\frac{d\theta}{\sqrt s}$就越小。

#### 6.7.2 图示效果

![img](https://pic4.zhimg.com/v2-8c73d061a42a65530c75e2378fdcc469_b.webp)

图中saddle point是鞍点，白球为$RMSprop$（近似），蓝球为普通梯度下降。图源同上。

其实图中的白球并非真的$RMSprop$，而是$RMSprop$改进前的$Adagrad$。不过由于两者比较相似，所以就用这个来代替。两者的主要区别也就是$RMSprop$更快一点而已。

#### 6.7.3 实现

具体实现时，由于出现了除法，所以为了避免除以0（或者除以极小数）出现，参数的更新公式更改为：

$$\theta = \theta - \alpha \frac{d\theta}{\sqrt{s+\epsilon}}$$

其中$\epsilon$为一个较小的值。

代码实现：

```python
# 需要参数：学习率alpha和衰减率beta_2，beta_2通常取0.999
# 以及epsilon一般取1e-8，很少进行调试更改
# 在梯度下降的循环里面
# 已经计算了梯度dW和db
# s_dW和s_db初始化为0，shape分别和dW，db一致
s_dw = beta_2 * s_dw + (1-beta_2) * dW**2
s_db = beta_2 * s_db + (1-beta_2) * db**2
W = W - alpha * (dW / np.sqrt(s_dw + epsilon))
b = b - alpha * (db / np.sqrt(s_db + epsilon))
```

### 6.8 $Adam$优化算法

#### 6.8.1 原理

$Adam$全称$Adaptive$ $Moment$ $Estimation$。该优化算法结合了$Momentum$和$RMSprop$，两者的优点兼顾。不仅可以跨越障碍，还能对所有特征都以相当的速度学习。结合了两者的优点之后，已经成为了近几年优化算法的常用选择。

#### 6.8.2 实现

代码实现：

```python
# 需要参数：学习率alpha、一阶矩梯度和的衰减率beta_1 和 二阶矩梯度平方和的衰减率beta_2。
# beta_1通常取0.9，beta_2通常取0.999；以及epsilon一般取1e-8，很少进行调试更改
# 在梯度下降的循环里面
# 已经计算了梯度dW和db
# v_dw,s_dW和v_db,s_db初始化为0，shape分别和dW，db一致
# t是当前迭代的次数。即第t个batch
v_dW = beta_1 * v_dW + (1 - beta_1)*dW
v_db = beta_1 * v_db + (1 - beta_1)*db
s_dW = beta_2 * s_dW + (1 - beta_2) * dW**2
s_db = beta_2 * s_db + (1 - beta_2) * db**2

#偏差修正x = x / (1 - b^t)
v_corrected_dW = v_dW / (1 - beta_1**t)
v_corrected_db = v_db / (1 - beta_1**t)
s_corrected_dW = s_dW / (1 - beta_2**t)
s_corrected_db = s_db / (1 - beta_2**t)

W = W - alpha * (v_corrected_dW / np.sqrt(s_corrected_dW + epsilon))
b = b - alpha * (v_corrected_db / np.sqrt(s_corrected_db + epsilon))
```

#### 6.8.3 后续

除了上述比较主流的优化算法，还有诸如$NAG$、$AdaGrad$等等。而近几年的$Adam$够好了吗？还不够。虽然收敛的很快，也很稳定，但是收敛的效果差（即收敛到的最优解的准确率偏低）。带动量的随机梯度下降$SGDM$的收敛效果就比$Adam$好。

既然知道有缺点，那就肯定会有新的算法的提出：比如$AMSGrad$和$AdaBound$。后者是目前来说比较有希望顶替$Adam$的：前期和$Adam$一样快，后期有和$SGD$一样的精度。

最后，对比一下各个算法的效果：

![SGD with momentum](http://sebastianruder.com/content/images/2016/09/saddle_point_evaluation_optimizers.gif)

![SGD without momentum](http://sebastianruder.com/content/images/2016/09/contours_evaluation_optimizers.gif)

图源[这里](https://twitter.com/alecrad)，是一个外网可能访问不了。顺带一提，这里也可以看出虽然同样收敛了，却不完全收敛到了同一个点，还是有差别的。

### 6.9 学习率衰减

#### 6.9.1 为什么

我们之前接触的学习率都是不变的，这可能会导致一个问题：学习率过大，前期虽然学习快但是后期波动大，难以收敛到最优；学习率太小后期虽然容易到达最优，前期却学习过慢。

所以学习率衰减就诞生了，为了前期能采用大的学习率加快速学习，后期能采用小的学习率收敛至最优。

#### 6.9.2 衰减方法

1. 常用的衰减公式：
   $$\alpha = \frac{1}{1 + decay\_rate * epoch\_num}\alpha_0$$
   其中$\alpha_0$为初始学习率，每经历一个$epoch$衰减一次。decay-rate称为衰减率，epoch_num为代数。这个衰减率是另一个需要调整的超参数。

2. 指数衰减：
   $$\alpha = k^{epoch\_num} \alpha_0$$
   同上。其中$k$为小数常数，通常取0.95。

3. 离散下降：
   $\alpha = 0.5\alpha$

4. 其他：
   $\alpha = \frac{k}{\sqrt{epoch\_num}} \alpha_0$
   或者

   $\alpha = \frac{k}{\sqrt{t}}\alpha_0$

   其中$t$表示当前为第$t$个$batch$。

### 6.10 局部最优问题

#### 6.10.1 局部最优点和鞍点

![](https://upload-images.jianshu.io/upload_images/24435917-64b14f00c1519cdb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

我们可以用一张图来解释。假设我们想优化两个参数$W_1$，$W_2$，平面的高度代表优化目标：损失函数。在这个两个维度的图中，就容易出现有多个梯度为零的点，即局部最优点，而不是实际上成本函数最小的零梯度点，也就是图中z值最小的全局最优点。

![](https://upload-images.jianshu.io/upload_images/24435917-bdd4e7042e20960c.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

但是在一个高维度空间的函数里，我们获得局部最优点的概率是很小的，通常梯度为零的点就是鞍点。从上图中可以看出，高维度空间里有的曲线会向上弯曲，另一些方向曲线向下弯，而不太可能是所有的都向上弯曲，因此更可能形成一个马鞍的形状，碰到鞍点，显然这个梯度为0的鞍点并不算什么最优点。

所以在深度学习中，我们对低维度空间的大部分直觉，并不能应用到高维度空间中。

适用于其它算法，如果神经网络中有2万个参数，那么$J$函数有2万个维度向量，网络更可能遇到鞍点，而不是局部最优点。

#### 6.10.2 深度学习中的平稳段问题

![3.JPG](https://upload-images.jianshu.io/upload_images/24435917-54a48c4d33309e39.JPG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

如果局部最优不是问题，那么真正的问题是什么？结果是平稳段会减缓学习，平稳段是一块区域，其中导数长时间接近于0，梯度会从曲面从从上向下下降，因为梯度等于或接近0，曲面很平坦，算法得花上非常长的时间慢慢走出平稳段。到达鞍点，再继续下降。这使得学习十分缓慢。

![4.png](https://upload-images.jianshu.io/upload_images/24435917-8ebef95ccc44367d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

所以相比于栽到最优点和鞍点上，优化算法更有可能载到这种类似平坦区的地形中。更糟糕的是，由于高维地形难以可视化，还有很多更复杂的未知地形会导致假收敛。

**所以说，在深度学习中，与其担忧模型陷入局部最优点怎么跳出来，更不如去好好考虑：**

1. 如何去设计一个尽量没有“平坦区”等危险地形的loss空间，即着手于loss函数的设计以及深度学习模型的设计；
2. 尽量让模型的初始化点远离空间中的危险地带，让最优化游戏开始于简单模式，即着手于模型参数的初始化策略；
3. 让最优化过程更智能一点，该加速冲时加速冲，该大胆跳跃时就大胆跳，该慢慢踱步时慢慢走，对危险地形有一定的判断力，如梯度截断策略；
4. 加速收敛策略，如下一章的batch normalization策略等。



### 6.11 编程实现mini-batch分割数据集和优化梯度下降算法

#### 6.11.1 目标

我们要做的是在分割数据集后，分别利用mini-batch梯度下降法，动量梯度下降法，结合RMSProp的Adam梯度下降法来优化算法。代码模块如下：

1. 导入库函数，构造神经网络模型
2. 分割数据集（mini-batch）
3. 优化梯度下降算法：
- mini-batch梯度下降法
- 使用具有动量的梯度下降算法
- 结合RMSProp的Adam算法
4. 调用优化算法，进行测试

#### 6.11.2 导入库函数，构造神经网络模型

- **导入库函数**
```python
# -*- coding: utf-8 -*-

import numpy as np
import matplotlib.pyplot as plt
import math

import opt_utils #需要用到的数据包
import testCase  #数据包

plt.rcParams['figure.figsize'] = (7.0, 4.0) #设置图像大小等信息
plt.rcParams['image.interpolation'] = 'nearest'
plt.rcParams['image.cmap'] = 'gray'
```
- **构造神经网络模型，按需要的优化算法进行调用**
```python
def model(X,Y,layers_dims,optimizer,learning_rate=0.0007,
          mini_batch_size=64,beta=0.9,beta1=0.9,beta2=0.999,
          epsilon=1e-8,num_epochs=60000,print_cost=True,is_plot=True):
    
    """
    可以运行在不同优化器模式下的3层神经网络模型。
    
    参数：
        X - 输入数据，维度为（2，输入的数据集里面样本数量）
        Y - 与X对应的标签
        layers_dims - 包含层数和节点数量的列表
        optimizer - 字符串类型的参数，用于选择优化类型，【 "gd" | "momentum" | "adam" 】
        learning_rate - 学习率
        mini_batch_size - 每个小批量数据集的大小
        beta - 用于动量优化的一个超参数
        beta1 - 用于计算梯度后的指数衰减的估计的超参数
        beta1 - 用于计算平方梯度后的指数衰减的估计的超参数
        epsilon - 用于在Adam中避免除零操作的超参数，一般不更改
        num_epochs - 整个训练集的遍历次数，（视频2.9学习率衰减，1分55秒处，视频中称作“代”）,相当于之前的num_iteration
        print_cost - 是否打印误差值，每遍历1000次数据集打印一次，但是每100次记录一个误差值，又称每1000代打印一次
        is_plot - 是否绘制出曲线图
        
    返回：
        parameters - 包含了学习后的参数
        
    """
    L = len(layers_dims)
    costs = []
    t = 0 #每学习完一个minibatch就增加1
    seed = 10 #随机种子
    
    #初始化参数
    parameters = opt_utils.initialize_parameters(layers_dims)
    
    #选择优化器
    if optimizer == "gd":
        pass #不使用任何优化器，直接使用梯度下降法
    elif optimizer == "momentum":
        v = initialize_velocity(parameters) #使用动量
    elif optimizer == "adam":
        v, s = initialize_adam(parameters)#使用Adam优化
    else:
        print("optimizer参数错误，程序退出。")
        exit(1)
    
    #开始学习
    for i in range(num_epochs):
        #定义随机 minibatches,我们在每次遍历数据集之后增加种子以重新排列数据集，使每次数据的顺序都不同
        seed = seed + 1
        minibatches = random_mini_batches(X,Y,mini_batch_size,seed)
        
        for minibatch in minibatches:
            #选择一个minibatch
            (minibatch_X,minibatch_Y) = minibatch
            
            #前向传播
            A3 , cache = opt_utils.forward_propagation(minibatch_X,parameters)
            
            #计算误差
            cost = opt_utils.compute_cost(A3 , minibatch_Y)
            
            #反向传播
            grads = opt_utils.backward_propagation(minibatch_X,minibatch_Y,cache)
            
            #更新参数
            if optimizer == "gd":
                parameters = update_parameters_with_gd(parameters,grads,learning_rate)
            elif optimizer == "momentum":
                parameters, v = update_parameters_with_momentun(parameters,grads,v,beta,learning_rate)
            elif optimizer == "adam":
                t = t + 1 
                parameters , v , s = update_parameters_with_adam(parameters,grads,v,s,t,learning_rate,beta1,beta2,epsilon)
        #记录误差值
        if i % 100 == 0:
            costs.append(cost)
            #是否打印误差值
            if print_cost and i % 1000 == 0:
                print("第" + str(i) + "次遍历整个数据集，当前误差值：" + str(cost))
    #是否绘制曲线图
    if is_plot:
        plt.plot(costs)
        plt.ylabel('cost')
        plt.xlabel('epochs (per 100)')
        plt.title("Learning rate = " + str(learning_rate))
        plt.show()
    
    return parameters
```
#### 6.11.3 mini-batch的实现
```python
def random_mini_batches(X,Y,mini_batch_size,seed):
    """
    从（X，Y）中创建一个随机的mini-batch列表
    
    参数：
        X - 输入数据，维度为(输入节点数量，样本的数量)
        Y - 对应的是X的标签，如【1 | 0】（蓝|红），维度为(1,样本的数量)
        mini_batch_size - 每个mini-batch的样本数量
        
    返回：
        mini-bacthes - 一个同步列表，维度为([mini_batch_X],[mini_batch_Y])，索引为对应的一个batch
    """
    
    np.random.seed(seed) #指定随机种子，不同种子数下生成的随机数组不同
    #此处目的为每次遍历数据集之后增加种子以重新排列数据集，使每次数据的顺序都不同
    m = X.shape[1] #行数，即样本数
    mini_batches = []
    
    #第一步：打乱顺序
    permutation = list(np.random.permutation(m)) #它会返回一个长度为m的随机数组，且里面的数是0到m-1
    shuffled_X = X[:,permutation]   #将每一列的数据按permutation的顺序来重新排列。
    shuffled_Y = Y[:,permutation].reshape((1,m))
        
    #第二步，分割
    num_complete_minibatches = math.floor(m / mini_batch_size) #把你的训练集分割成多少份。floor求整：请注意，如果值是99.99，那么返回值是99，剩下的0.99会被舍弃
    for k in range(0,num_complete_minibatches):
        mini_batch_X = shuffled_X[:,k * mini_batch_size:(k+1)*mini_batch_size]
        mini_batch_Y = shuffled_Y[:,k * mini_batch_size:(k+1)*mini_batch_size]

        mini_batch = (mini_batch_X,mini_batch_Y) #一个单独的mini-batch
        mini_batches.append(mini_batch) #在列表末尾添加新的对象。
    
    #如果训练集的大小刚好是mini_batch_size的整数倍，那么这里已经处理完了
    #如果训练集的大小不是mini_batch_size的整数倍，那么最后肯定会剩下一些，我们要把它处理了
    if m % mini_batch_size != 0:
        #获取最后剩余的部分
        mini_batch_X = shuffled_X[:,mini_batch_size * num_complete_minibatches:]
        mini_batch_Y = shuffled_Y[:,mini_batch_size * num_complete_minibatches:]
        
        mini_batch = (mini_batch_X,mini_batch_Y)
        mini_batches.append(mini_batch)
        
    return mini_batches
```
#### 6.11.4 优化梯度下降算法的实现

- 梯度下降算法

```python
def update_parameters_with_gd(parameters,grads,learning_rate):
    """
    使用梯度下降更新参数
    
    参数：
        parameters - 字典，包含了要更新的参数：
            parameters['W' + str(l)] = Wl
            parameters['b' + str(l)] = bl
        grads - 字典，包含了每一个梯度值用以更新参数
            grads['dW' + str(l)] = dWl
            grads['db' + str(l)] = dbl
        learning_rate - 学习率
        
    返回值：
        parameters - 字典，包含了更新后的参数
    """
    
    L = len(parameters) // 2 #神经网络的层数
    
    #更新每个参数
    for l in range(L): #计算每一层网络的相应参数
        parameters["W" + str(l +1)] = parameters["W" + str(l + 1)] - learning_rate * grads["dW" + str(l + 1)]
        parameters["b" + str(l +1)] = parameters["b" + str(l + 1)] - learning_rate * grads["db" + str(l + 1)]
    
    return parameters
```
- $Momentum$梯度下降法
初始化速度
```python
def initialize_velocity(parameters):
    """
    初始化速度，velocity是一个字典：
        - keys: "dW1", "db1", ..., "dWL", "dbL" 
        - values:与相应的梯度/参数维度相同的值为零的矩阵。
    参数：
        parameters - 一个字典，包含了以下参数：
            parameters["W" + str(l)] = Wl
            parameters["b" + str(l)] = bl
    返回:
        v - 一个字典变量，包含了以下参数：
            v["dW" + str(l)] = dWl的速度
            v["db" + str(l)] = dbl的速度
    
    """
    L = len(parameters) // 2 #神经网络的层数
    v = {}
    
    for l in range(L):
        v["dW" + str(l + 1)] = np.zeros_like(parameters["W" + str(l + 1)])
        v["db" + str(l + 1)] = np.zeros_like(parameters["b" + str(l + 1)])
    
    return v

```
利用动量更新，影响梯度的方向：
```python
def update_parameters_with_momentun(parameters,grads,v,beta,learning_rate):
    """
    使用动量更新参数
    参数：
        parameters - 一个字典类型的变量，包含了以下字段：
            parameters["W" + str(l)] = Wl
            parameters["b" + str(l)] = bl
        grads - 一个包含梯度值的字典变量，具有以下字段：
            grads["dW" + str(l)] = dWl
            grads["db" + str(l)] = dbl
        v - 包含当前速度的字典变量，具有以下字段：
            v["dW" + str(l)] = ...
            v["db" + str(l)] = ...
        beta - 超参数，动量，实数
        learning_rate - 学习率，实数
    返回：
        parameters - 更新后的参数字典
        v - 包含了更新后的速度变量
    """
    L = len(parameters) // 2 
    for l in range(L):
        #计算速度，因为之前初始化过程已经记录了真实值v，所以这里直接 v["dW" + str(l + 1)]更新
        v["dW" + str(l + 1)] = beta * v["dW" + str(l + 1)] + (1 - beta) * grads["dW" + str(l + 1)]
        v["db" + str(l + 1)] = beta * v["db" + str(l + 1)] + (1 - beta) * grads["db" + str(l + 1)]
        
        #更新参数
        parameters["W" + str(l + 1)] = parameters["W" + str(l + 1)] - learning_rate * v["dW" + str(l + 1)]
        parameters["b" + str(l + 1)] = parameters["b" + str(l + 1)] - learning_rate * v["db" + str(l + 1)]
    
    return parameters,v

```

- $Adam$算法

初始化Adam所需参数：
```python
def initialize_adam(parameters):
    """
    初始化v和s，它们都是字典类型的变量，都包含了以下字段：
        - keys: "dW1", "db1", ..., "dWL", "dbL" 
        - values：与对应的梯度/参数相同维度的值为零的numpy矩阵
    
    参数：
        parameters - 包含了以下参数的字典变量：
            parameters["W" + str(l)] = Wl
            parameters["b" + str(l)] = bl
    返回：
        v - 包含梯度的指数加权平均值，字段如下：
            v["dW" + str(l)] = ...
            v["db" + str(l)] = ...
        s - 包含平方梯度的指数加权平均值，字段如下：
            s["dW" + str(l)] = ...
            s["db" + str(l)] = ...
    
    """
    
    L = len(parameters) // 2
    v = {}
    s = {}
    
    for l in range(L):
        v["dW" + str(l + 1)] = np.zeros_like(parameters["W" + str(l + 1)])
        v["db" + str(l + 1)] = np.zeros_like(parameters["b" + str(l + 1)])
        
        s["dW" + str(l + 1)] = np.zeros_like(parameters["W" + str(l + 1)])
        s["db" + str(l + 1)] = np.zeros_like(parameters["b" + str(l + 1)])
    
    return (v,s)


```
参数更新：
```python
def update_parameters_with_adam(parameters,grads,v,s,t,learning_rate=0.01,beta1=0.9,beta2=0.999,epsilon=1e-8):
    """
    使用Adam更新参数
    
    参数：
        parameters - 包含了以下字段的字典：
            parameters['W' + str(l)] = Wl
            parameters['b' + str(l)] = bl
        grads - 包含了梯度值的字典，有以下key值：
            grads['dW' + str(l)] = dWl
            grads['db' + str(l)] = dbl
        v - Adam的变量，第一个梯度的移动平均值，是一个字典类型的变量
        s - Adam的变量，平方梯度的移动平均值，是一个字典类型的变量
        t - 当前迭代的次数
        learning_rate - 学习率
        beta1 - 动量，超参数,用于第一阶段，使得曲线的Y值不从0开始（参见天气数据的那个图）
        beta2 - RMSprop的一个参数，超参数
        epsilon - 防止除零操作（分母为0）
    
    返回：
        parameters - 更新后的参数
        v - 第一个梯度的移动平均值，是一个字典类型的变量
        s - 平方梯度的移动平均值，是一个字典类型的变量
    """
    L = len(parameters) // 2
    v_corrected = {} #偏差修正后的值
    s_corrected = {} #偏差修正后的值
    
    for l in range(L):
        #梯度的移动平均值,输入："v , grads , beta1",输出：" v "
        v["dW" + str(l + 1)] = beta1 * v["dW" + str(l + 1)] + (1 - beta1) * grads["dW" + str(l + 1)]
        v["db" + str(l + 1)] = beta1 * v["db" + str(l + 1)] + (1 - beta1) * grads["db" + str(l + 1)]
        
        #计算第一阶段的偏差修正后的估计值，输入"v , beta1 , t" , 输出："v_corrected"
        v_corrected["dW" + str(l + 1)] = v["dW" + str(l + 1)] / (1 - np.power(beta1,t))
        v_corrected["db" + str(l + 1)] = v["db" + str(l + 1)] / (1 - np.power(beta1,t))
    
        #计算平方梯度的移动平均值，输入："s, grads , beta2"，输出："s"
        s["dW" + str(l + 1)] = beta2 * s["dW" + str(l + 1)] + (1 - beta2) * np.square(grads["dW" + str(l + 1)])
        s["db" + str(l + 1)] = beta2 * s["db" + str(l + 1)] + (1 - beta2) * np.square(grads["db" + str(l + 1)])
         
        #计算第二阶段的偏差修正后的估计值，输入："s , beta2 , t"，输出："s_corrected"
        s_corrected["dW" + str(l + 1)] = s["dW" + str(l + 1)] / (1 - np.power(beta2,t))
        s_corrected["db" + str(l + 1)] = s["db" + str(l + 1)] / (1 - np.power(beta2,t))
        
        #更新参数，输入: "parameters, learning_rate, v_corrected, s_corrected, epsilon". 输出: "parameters".
        parameters["W" + str(l + 1)] = parameters["W" + str(l + 1)] - learning_rate * (v_corrected["dW" + str(l + 1)] / np.sqrt(s_corrected["dW" + str(l + 1)] + epsilon))
        parameters["b" + str(l + 1)] = parameters["b" + str(l + 1)] - learning_rate * (v_corrected["db" + str(l + 1)] / np.sqrt(s_corrected["db" + str(l + 1)] + epsilon))
    
    return (parameters,v,s)

```

#### 6.11.5 调用优化算法，效果对比

- **加载数据集**
```python
train_X, train_Y = opt_utils.load_dataset(is_plot=True)
```
训练集分布情况如图所示：

![1.png](https://upload-images.jianshu.io/upload_images/24435917-97178d598bd091ad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

以下算法均预先使用了mini-batch梯度下降。

- **未使用优化算法的梯度下降**
```python
layers_dims = [train_X.shape[0],5,2,1]
parameters = model(train_X, train_Y, layers_dims, optimizer="gd",is_plot=True)
```
算法收敛情况和分类情况如图所示：

![21.png](https://upload-images.jianshu.io/upload_images/24435917-c7d2cba732404f8b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![22.png](https://upload-images.jianshu.io/upload_images/24435917-3b850fca6240e386.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

- **使用动量的梯度下降**
```python
layers_dims = [train_X.shape[0],5,2,1]
parameters = model(train_X, train_Y, layers_dims, beta=0.9,optimizer="momentum",is_plot=True)
```
算法收敛情况和分类情况如图所示：

![31.png](https://upload-images.jianshu.io/upload_images/24435917-1d1c6caae738ec7c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![32.png](https://upload-images.jianshu.io/upload_images/24435917-37be9c1ec7f17cad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

由于本例使用的数据情况较为简单，学习率较小，使用了动量的梯度下降作用不大。

- **Adam优化后的梯度下降**
```python
layers_dims = [train_X.shape[0], 5, 2, 1]
parameters = model(train_X, train_Y, layers_dims, optimizer="adam",is_plot=True)
```
算法收敛情况和分类情况如图所示：

![41.png](https://upload-images.jianshu.io/upload_images/24435917-b7bb2aa8822613b2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![42.png](https://upload-images.jianshu.io/upload_images/24435917-4b19a92d0eec4007.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

|优化算法|	准确度	|曲线平滑度|
| :-: | :-:| :-: |
|梯度下降	|79.7%|	震荡|
|具有动量的梯度下降算法	|79.7%	|震荡|
|Adam优化后的梯度下降	|94%	|平滑|

以上设置迭代次数为10000次，可以看出$adam$算法曲线已经平滑，而另外两种算法还未收敛。当迭代次数增加为60000次时，三种算法均达收敛：

|优化算法|	准确度	|曲线平滑度|
| :-: | :-:| :-: |
|梯度下降	|93.3%|	平滑|
|具有动量的梯度下降算法	|93.3%	|平滑|
|Adam优化后的梯度下降	|94.3%	|平滑|